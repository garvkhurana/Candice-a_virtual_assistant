{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8a15b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, AutoConfig\n",
    "from torch.optim import AdamW\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    input_dir: str = \"images_for_finetuning\"\n",
    "    output_dir: str = \"classifier_finetuned\"\n",
    "    model_name: str = \"microsoft/resnet-50\"  \n",
    "    train_batch_size: int = 8\n",
    "    eval_batch_size: int = 4\n",
    "    num_epochs: int = 5\n",
    "    learning_rate: float = 2e-5\n",
    "    image_size: int = 224  \n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a0d8de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonDataset(Dataset):\n",
    "    def __init__(self, root_dir, processor, image_size=224):\n",
    "        self.root_dir = root_dir\n",
    "        self.processor = processor\n",
    "        self.image_size = image_size\n",
    "        self.samples = []\n",
    "\n",
    "        if not os.path.exists(root_dir):\n",
    "            raise FileNotFoundError(f\"Directory '{root_dir}' not found. Please create the directory and add your image data.\")\n",
    "\n",
    "        class_dirs = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "        if not class_dirs:\n",
    "            raise ValueError(f\"No class directories found in '{root_dir}'\")\n",
    "\n",
    "        for label in class_dirs:\n",
    "            class_dir = os.path.join(root_dir, label)\n",
    "            for img_file in os.listdir(class_dir):\n",
    "                if img_file.lower().endswith(('.jpeg', '.jpg', '.png', '.bmp', '.tiff')):\n",
    "                    self.samples.append((os.path.join(class_dir, img_file), label))\n",
    "\n",
    "        if not self.samples:\n",
    "            raise ValueError(f\"No images found in '{root_dir}'. Please check your directory structure.\")\n",
    "\n",
    "        self.label2id = {label: idx for idx, label in enumerate(sorted(class_dirs))}\n",
    "        self.id2label = {v: k for k, v in self.label2id.items()}\n",
    "        \n",
    "        print(f\"Found {len(self.samples)} images across {len(self.label2id)} classes:\")\n",
    "        for label, idx in self.label2id.items():\n",
    "            count = sum(1 for _, l in self.samples if l == label)\n",
    "            print(f\"  {label}: {count} images (id: {idx})\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            \n",
    "            inputs = self.processor(image, return_tensors=\"pt\")\n",
    "            \n",
    "            return {\n",
    "                'pixel_values': inputs['pixel_values'].squeeze(0),  # Remove batch dimension\n",
    "                'labels': torch.tensor(self.label2id[label], dtype=torch.long)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {img_path}: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51af6e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    pixel_values = torch.stack([item['pixel_values'] for item in batch])\n",
    "    labels = torch.stack([item['labels'] for item in batch])\n",
    "    \n",
    "    return {\n",
    "        'pixel_values': pixel_values,\n",
    "        'labels': labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9218568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Found 5000 images across 50 classes:\n",
      "  AirPods: 100 images (id: 0)\n",
      "  Android_phone: 100 images (id: 1)\n",
      "  CD_player: 100 images (id: 2)\n",
      "  DVD_player: 100 images (id: 3)\n",
      "  Lightning_cable: 100 images (id: 4)\n",
      "  TV_remote_control: 100 images (id: 5)\n",
      "  USB-C_cable: 100 images (id: 6)\n",
      "  air_freshener_dispenser: 100 images (id: 7)\n",
      "  air_fryer: 100 images (id: 8)\n",
      "  blood_pressure_monitor: 100 images (id: 9)\n",
      "  bluetooth_speaker: 100 images (id: 10)\n",
      "  calculator: 100 images (id: 11)\n",
      "  car_charger: 100 images (id: 12)\n",
      "  computer_mouse: 100 images (id: 13)\n",
      "  digital_thermometer: 100 images (id: 14)\n",
      "  electric_fan: 100 images (id: 15)\n",
      "  electric_kettle: 100 images (id: 16)\n",
      "  electric_toothbrush: 100 images (id: 17)\n",
      "  fitness_tracker: 100 images (id: 18)\n",
      "  food_scale: 100 images (id: 19)\n",
      "  hair_dryer: 100 images (id: 20)\n",
      "  hand_mixer: 100 images (id: 21)\n",
      "  headphones: 100 images (id: 22)\n",
      "  iPhone: 100 images (id: 23)\n",
      "  iPhone_charger: 100 images (id: 24)\n",
      "  juicer: 100 images (id: 25)\n",
      "  kitchen_blender: 100 images (id: 26)\n",
      "  laptop_charger: 100 images (id: 27)\n",
      "  laptop_computer: 100 images (id: 28)\n",
      "  mechanical_keyboard: 100 images (id: 29)\n",
      "  micro_USB_cable: 100 images (id: 30)\n",
      "  microwave: 100 images (id: 31)\n",
      "  nail_clipper: 100 images (id: 32)\n",
      "  phone_charger: 100 images (id: 33)\n",
      "  power_bank: 100 images (id: 34)\n",
      "  printer: 100 images (id: 35)\n",
      "  scanner: 100 images (id: 36)\n",
      "  security_camera: 100 images (id: 37)\n",
      "  smart_light_bulb: 100 images (id: 38)\n",
      "  smart_speaker: 100 images (id: 39)\n",
      "  smartwatch: 100 images (id: 40)\n",
      "  soundbar: 100 images (id: 41)\n",
      "  stand_mixer: 100 images (id: 42)\n",
      "  toaster: 100 images (id: 43)\n",
      "  vacuum_cleaner: 100 images (id: 44)\n",
      "  weighing_scale: 100 images (id: 45)\n",
      "  wifi_router: 100 images (id: 46)\n",
      "  wireless_charger: 100 images (id: 47)\n",
      "  wireless_earbuds: 100 images (id: 48)\n",
      "  wireless_mouse: 100 images (id: 49)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([50]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([50, 2048]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 5 epochs...\n",
      "Total batches per epoch: 625\n",
      "Epoch [1/5], Batch [0/625], Loss: 3.9364, Accuracy: 0.00%\n",
      "Epoch [1/5], Batch [5/625], Loss: 3.9532, Accuracy: 0.00%\n",
      "Epoch [1/5], Batch [10/625], Loss: 3.9348, Accuracy: 1.14%\n",
      "Epoch [1/5], Batch [15/625], Loss: 3.9608, Accuracy: 0.78%\n",
      "Epoch [1/5], Batch [20/625], Loss: 3.9661, Accuracy: 1.19%\n",
      "Epoch [1/5], Batch [25/625], Loss: 3.8751, Accuracy: 1.44%\n",
      "Epoch [1/5], Batch [30/625], Loss: 3.9434, Accuracy: 1.61%\n",
      "Epoch [1/5], Batch [35/625], Loss: 3.8970, Accuracy: 2.08%\n",
      "Epoch [1/5], Batch [40/625], Loss: 3.9276, Accuracy: 1.83%\n",
      "Epoch [1/5], Batch [45/625], Loss: 3.9337, Accuracy: 1.90%\n",
      "Epoch [1/5], Batch [50/625], Loss: 3.8734, Accuracy: 1.72%\n",
      "Epoch [1/5], Batch [55/625], Loss: 3.9360, Accuracy: 1.56%\n",
      "Epoch [1/5], Batch [60/625], Loss: 3.9308, Accuracy: 1.43%\n",
      "Epoch [1/5], Batch [65/625], Loss: 3.8939, Accuracy: 1.52%\n",
      "Epoch [1/5], Batch [70/625], Loss: 3.9600, Accuracy: 1.41%\n",
      "Epoch [1/5], Batch [75/625], Loss: 3.9189, Accuracy: 1.32%\n",
      "Epoch [1/5], Batch [80/625], Loss: 3.9204, Accuracy: 1.23%\n",
      "Epoch [1/5], Batch [85/625], Loss: 3.8552, Accuracy: 1.31%\n",
      "Epoch [1/5], Batch [90/625], Loss: 3.8965, Accuracy: 1.24%\n",
      "Epoch [1/5], Batch [95/625], Loss: 3.9105, Accuracy: 1.30%\n",
      "Epoch [1/5], Batch [100/625], Loss: 3.9108, Accuracy: 1.36%\n",
      "Epoch [1/5], Batch [105/625], Loss: 3.8583, Accuracy: 1.42%\n",
      "Epoch [1/5], Batch [110/625], Loss: 3.9074, Accuracy: 1.35%\n",
      "Epoch [1/5], Batch [115/625], Loss: 3.9197, Accuracy: 1.51%\n",
      "Epoch [1/5], Batch [120/625], Loss: 3.9284, Accuracy: 1.65%\n",
      "Epoch [1/5], Batch [125/625], Loss: 3.8997, Accuracy: 1.88%\n",
      "Epoch [1/5], Batch [130/625], Loss: 3.9277, Accuracy: 1.91%\n",
      "Epoch [1/5], Batch [135/625], Loss: 3.8843, Accuracy: 1.93%\n",
      "Epoch [1/5], Batch [140/625], Loss: 3.8863, Accuracy: 1.95%\n",
      "Epoch [1/5], Batch [145/625], Loss: 3.9202, Accuracy: 2.05%\n",
      "Epoch [1/5], Batch [150/625], Loss: 3.9073, Accuracy: 2.07%\n",
      "Epoch [1/5], Batch [155/625], Loss: 3.8762, Accuracy: 2.24%\n",
      "Epoch [1/5], Batch [160/625], Loss: 3.8680, Accuracy: 2.25%\n",
      "Epoch [1/5], Batch [165/625], Loss: 3.8444, Accuracy: 2.18%\n",
      "Epoch [1/5], Batch [170/625], Loss: 3.9359, Accuracy: 2.12%\n",
      "Epoch [1/5], Batch [175/625], Loss: 3.8920, Accuracy: 2.13%\n",
      "Epoch [1/5], Batch [180/625], Loss: 3.8832, Accuracy: 2.35%\n",
      "Epoch [1/5], Batch [185/625], Loss: 3.9276, Accuracy: 2.42%\n",
      "Epoch [1/5], Batch [190/625], Loss: 3.9073, Accuracy: 2.62%\n",
      "Epoch [1/5], Batch [195/625], Loss: 3.8670, Accuracy: 2.68%\n",
      "Epoch [1/5], Batch [200/625], Loss: 3.8599, Accuracy: 2.74%\n",
      "Epoch [1/5], Batch [205/625], Loss: 3.8977, Accuracy: 2.85%\n",
      "Epoch [1/5], Batch [210/625], Loss: 3.9050, Accuracy: 2.84%\n",
      "Epoch [1/5], Batch [215/625], Loss: 3.9234, Accuracy: 2.89%\n",
      "Epoch [1/5], Batch [220/625], Loss: 3.9252, Accuracy: 2.88%\n",
      "Epoch [1/5], Batch [225/625], Loss: 3.9173, Accuracy: 2.88%\n",
      "Epoch [1/5], Batch [230/625], Loss: 3.8749, Accuracy: 2.87%\n",
      "Epoch [1/5], Batch [235/625], Loss: 3.8981, Accuracy: 2.97%\n",
      "Epoch [1/5], Batch [240/625], Loss: 3.8774, Accuracy: 3.06%\n",
      "Epoch [1/5], Batch [245/625], Loss: 3.9038, Accuracy: 3.05%\n",
      "Epoch [1/5], Batch [250/625], Loss: 3.9447, Accuracy: 3.09%\n",
      "Epoch [1/5], Batch [255/625], Loss: 3.8540, Accuracy: 3.03%\n",
      "Epoch [1/5], Batch [260/625], Loss: 3.8597, Accuracy: 3.16%\n",
      "Epoch [1/5], Batch [265/625], Loss: 3.8391, Accuracy: 3.20%\n",
      "Epoch [1/5], Batch [270/625], Loss: 3.9008, Accuracy: 3.23%\n",
      "Epoch [1/5], Batch [275/625], Loss: 3.9298, Accuracy: 3.22%\n",
      "Epoch [1/5], Batch [280/625], Loss: 3.9082, Accuracy: 3.16%\n",
      "Epoch [1/5], Batch [285/625], Loss: 3.8923, Accuracy: 3.23%\n",
      "Epoch [1/5], Batch [290/625], Loss: 3.8735, Accuracy: 3.26%\n",
      "Epoch [1/5], Batch [295/625], Loss: 3.8619, Accuracy: 3.29%\n",
      "Epoch [1/5], Batch [300/625], Loss: 3.9043, Accuracy: 3.28%\n",
      "Epoch [1/5], Batch [305/625], Loss: 3.8998, Accuracy: 3.27%\n",
      "Epoch [1/5], Batch [310/625], Loss: 3.8807, Accuracy: 3.34%\n",
      "Epoch [1/5], Batch [315/625], Loss: 3.8980, Accuracy: 3.36%\n",
      "Epoch [1/5], Batch [320/625], Loss: 3.8699, Accuracy: 3.35%\n",
      "Epoch [1/5], Batch [325/625], Loss: 3.9041, Accuracy: 3.30%\n",
      "Epoch [1/5], Batch [330/625], Loss: 3.8848, Accuracy: 3.32%\n",
      "Epoch [1/5], Batch [335/625], Loss: 3.8736, Accuracy: 3.31%\n",
      "Epoch [1/5], Batch [340/625], Loss: 3.9113, Accuracy: 3.34%\n",
      "Epoch [1/5], Batch [345/625], Loss: 3.8779, Accuracy: 3.43%\n",
      "Epoch [1/5], Batch [350/625], Loss: 3.8622, Accuracy: 3.45%\n",
      "Epoch [1/5], Batch [355/625], Loss: 3.8698, Accuracy: 3.58%\n",
      "Epoch [1/5], Batch [360/625], Loss: 3.8569, Accuracy: 3.67%\n",
      "Epoch [1/5], Batch [365/625], Loss: 3.9099, Accuracy: 3.72%\n",
      "Epoch [1/5], Batch [370/625], Loss: 3.8581, Accuracy: 3.81%\n",
      "Epoch [1/5], Batch [375/625], Loss: 3.8633, Accuracy: 3.86%\n",
      "Epoch [1/5], Batch [380/625], Loss: 3.8441, Accuracy: 4.00%\n",
      "Epoch [1/5], Batch [385/625], Loss: 3.8853, Accuracy: 4.02%\n",
      "Epoch [1/5], Batch [390/625], Loss: 3.8912, Accuracy: 4.03%\n",
      "Epoch [1/5], Batch [395/625], Loss: 3.8808, Accuracy: 4.07%\n",
      "Epoch [1/5], Batch [400/625], Loss: 3.8632, Accuracy: 4.05%\n",
      "Epoch [1/5], Batch [405/625], Loss: 3.8296, Accuracy: 4.16%\n",
      "Epoch [1/5], Batch [410/625], Loss: 3.8797, Accuracy: 4.29%\n",
      "Epoch [1/5], Batch [415/625], Loss: 3.8328, Accuracy: 4.39%\n",
      "Epoch [1/5], Batch [420/625], Loss: 3.8701, Accuracy: 4.42%\n",
      "Epoch [1/5], Batch [425/625], Loss: 3.8062, Accuracy: 4.43%\n",
      "Epoch [1/5], Batch [430/625], Loss: 3.8920, Accuracy: 4.50%\n",
      "Epoch [1/5], Batch [435/625], Loss: 3.9041, Accuracy: 4.56%\n",
      "Epoch [1/5], Batch [440/625], Loss: 3.8946, Accuracy: 4.51%\n",
      "Epoch [1/5], Batch [445/625], Loss: 3.8417, Accuracy: 4.54%\n",
      "Epoch [1/5], Batch [450/625], Loss: 3.8238, Accuracy: 4.60%\n",
      "Epoch [1/5], Batch [455/625], Loss: 3.8482, Accuracy: 4.61%\n",
      "Epoch [1/5], Batch [460/625], Loss: 3.8907, Accuracy: 4.61%\n",
      "Epoch [1/5], Batch [465/625], Loss: 3.8834, Accuracy: 4.59%\n",
      "Epoch [1/5], Batch [470/625], Loss: 3.8022, Accuracy: 4.78%\n",
      "Epoch [1/5], Batch [475/625], Loss: 3.8553, Accuracy: 4.78%\n",
      "Epoch [1/5], Batch [480/625], Loss: 3.8430, Accuracy: 4.83%\n",
      "Epoch [1/5], Batch [485/625], Loss: 3.8526, Accuracy: 4.89%\n",
      "Epoch [1/5], Batch [490/625], Loss: 3.8231, Accuracy: 4.99%\n",
      "Epoch [1/5], Batch [495/625], Loss: 3.8681, Accuracy: 5.02%\n",
      "Epoch [1/5], Batch [500/625], Loss: 3.8319, Accuracy: 5.14%\n",
      "Epoch [1/5], Batch [505/625], Loss: 3.8435, Accuracy: 5.19%\n",
      "Epoch [1/5], Batch [510/625], Loss: 3.8403, Accuracy: 5.23%\n",
      "Epoch [1/5], Batch [515/625], Loss: 3.8519, Accuracy: 5.35%\n",
      "Epoch [1/5], Batch [520/625], Loss: 3.8130, Accuracy: 5.45%\n",
      "Epoch [1/5], Batch [525/625], Loss: 3.8399, Accuracy: 5.51%\n",
      "Epoch [1/5], Batch [530/625], Loss: 3.8465, Accuracy: 5.48%\n",
      "Epoch [1/5], Batch [535/625], Loss: 3.8686, Accuracy: 5.60%\n",
      "Epoch [1/5], Batch [540/625], Loss: 3.8174, Accuracy: 5.71%\n",
      "Epoch [1/5], Batch [545/625], Loss: 3.8144, Accuracy: 5.75%\n",
      "Epoch [1/5], Batch [550/625], Loss: 3.8278, Accuracy: 5.85%\n",
      "Epoch [1/5], Batch [555/625], Loss: 3.8397, Accuracy: 5.87%\n",
      "Epoch [1/5], Batch [560/625], Loss: 3.8287, Accuracy: 5.93%\n",
      "Epoch [1/5], Batch [565/625], Loss: 3.8039, Accuracy: 5.94%\n",
      "Epoch [1/5], Batch [570/625], Loss: 3.8147, Accuracy: 6.13%\n",
      "Epoch [1/5], Batch [575/625], Loss: 3.8254, Accuracy: 6.14%\n",
      "Epoch [1/5], Batch [580/625], Loss: 3.7611, Accuracy: 6.22%\n",
      "Epoch [1/5], Batch [585/625], Loss: 3.8476, Accuracy: 6.23%\n",
      "Epoch [1/5], Batch [590/625], Loss: 3.8458, Accuracy: 6.24%\n",
      "Epoch [1/5], Batch [595/625], Loss: 3.8241, Accuracy: 6.25%\n",
      "Epoch [1/5], Batch [600/625], Loss: 3.8650, Accuracy: 6.30%\n",
      "Epoch [1/5], Batch [605/625], Loss: 3.7760, Accuracy: 6.31%\n",
      "Epoch [1/5], Batch [610/625], Loss: 3.8378, Accuracy: 6.34%\n",
      "Epoch [1/5], Batch [615/625], Loss: 3.8044, Accuracy: 6.43%\n",
      "Epoch [1/5], Batch [620/625], Loss: 3.8202, Accuracy: 6.50%\n",
      "\n",
      "Epoch [1/5] Summary:\n",
      "  Average Loss: 3.8763\n",
      "  Accuracy: 6.54%\n",
      "--------------------------------------------------\n",
      "Epoch [2/5], Batch [0/625], Loss: 3.8164, Accuracy: 12.50%\n",
      "Epoch [2/5], Batch [5/625], Loss: 3.8349, Accuracy: 10.42%\n",
      "Epoch [2/5], Batch [10/625], Loss: 3.8299, Accuracy: 14.77%\n",
      "Epoch [2/5], Batch [15/625], Loss: 3.8166, Accuracy: 17.97%\n",
      "Epoch [2/5], Batch [20/625], Loss: 3.8180, Accuracy: 16.67%\n",
      "Epoch [2/5], Batch [25/625], Loss: 3.8208, Accuracy: 16.35%\n",
      "Epoch [2/5], Batch [30/625], Loss: 3.7946, Accuracy: 16.53%\n",
      "Epoch [2/5], Batch [35/625], Loss: 3.7586, Accuracy: 16.67%\n",
      "Epoch [2/5], Batch [40/625], Loss: 3.8106, Accuracy: 18.29%\n",
      "Epoch [2/5], Batch [45/625], Loss: 3.7894, Accuracy: 18.75%\n",
      "Epoch [2/5], Batch [50/625], Loss: 3.7371, Accuracy: 18.87%\n",
      "Epoch [2/5], Batch [55/625], Loss: 3.7669, Accuracy: 18.30%\n",
      "Epoch [2/5], Batch [60/625], Loss: 3.8265, Accuracy: 17.83%\n",
      "Epoch [2/5], Batch [65/625], Loss: 3.7635, Accuracy: 17.42%\n",
      "Epoch [2/5], Batch [70/625], Loss: 3.7791, Accuracy: 17.43%\n",
      "Epoch [2/5], Batch [75/625], Loss: 3.8040, Accuracy: 17.43%\n",
      "Epoch [2/5], Batch [80/625], Loss: 3.8263, Accuracy: 17.75%\n",
      "Epoch [2/5], Batch [85/625], Loss: 3.8109, Accuracy: 17.88%\n",
      "Epoch [2/5], Batch [90/625], Loss: 3.7764, Accuracy: 17.86%\n",
      "Epoch [2/5], Batch [95/625], Loss: 3.8157, Accuracy: 17.71%\n",
      "Epoch [2/5], Batch [100/625], Loss: 3.7587, Accuracy: 17.95%\n",
      "Epoch [2/5], Batch [105/625], Loss: 3.7664, Accuracy: 18.16%\n",
      "Epoch [2/5], Batch [110/625], Loss: 3.8093, Accuracy: 17.79%\n",
      "Epoch [2/5], Batch [115/625], Loss: 3.8254, Accuracy: 17.35%\n",
      "Epoch [2/5], Batch [120/625], Loss: 3.7909, Accuracy: 17.77%\n",
      "Epoch [2/5], Batch [125/625], Loss: 3.7203, Accuracy: 17.96%\n",
      "Epoch [2/5], Batch [130/625], Loss: 3.7555, Accuracy: 18.23%\n",
      "Epoch [2/5], Batch [135/625], Loss: 3.7735, Accuracy: 18.57%\n",
      "Epoch [2/5], Batch [140/625], Loss: 3.8106, Accuracy: 18.53%\n",
      "Epoch [2/5], Batch [145/625], Loss: 3.7430, Accuracy: 18.84%\n",
      "Epoch [2/5], Batch [150/625], Loss: 3.7361, Accuracy: 18.87%\n",
      "Epoch [2/5], Batch [155/625], Loss: 3.7297, Accuracy: 19.07%\n",
      "Epoch [2/5], Batch [160/625], Loss: 3.8044, Accuracy: 19.18%\n",
      "Epoch [2/5], Batch [165/625], Loss: 3.7812, Accuracy: 19.28%\n",
      "Epoch [2/5], Batch [170/625], Loss: 3.7241, Accuracy: 19.23%\n",
      "Epoch [2/5], Batch [175/625], Loss: 3.8033, Accuracy: 19.18%\n",
      "Epoch [2/5], Batch [180/625], Loss: 3.7992, Accuracy: 19.20%\n",
      "Epoch [2/5], Batch [185/625], Loss: 3.8188, Accuracy: 19.22%\n",
      "Epoch [2/5], Batch [190/625], Loss: 3.7298, Accuracy: 19.18%\n",
      "Epoch [2/5], Batch [195/625], Loss: 3.8055, Accuracy: 19.26%\n",
      "Epoch [2/5], Batch [200/625], Loss: 3.6770, Accuracy: 19.47%\n",
      "Epoch [2/5], Batch [205/625], Loss: 3.7591, Accuracy: 19.60%\n",
      "Epoch [2/5], Batch [210/625], Loss: 3.7625, Accuracy: 19.91%\n",
      "Epoch [2/5], Batch [215/625], Loss: 3.7758, Accuracy: 20.14%\n",
      "Epoch [2/5], Batch [220/625], Loss: 3.7407, Accuracy: 20.19%\n",
      "Epoch [2/5], Batch [225/625], Loss: 3.8165, Accuracy: 20.30%\n",
      "Epoch [2/5], Batch [230/625], Loss: 3.7216, Accuracy: 20.29%\n",
      "Epoch [2/5], Batch [235/625], Loss: 3.7827, Accuracy: 20.29%\n",
      "Epoch [2/5], Batch [240/625], Loss: 3.7222, Accuracy: 20.54%\n",
      "Epoch [2/5], Batch [245/625], Loss: 3.7468, Accuracy: 20.68%\n",
      "Epoch [2/5], Batch [250/625], Loss: 3.7460, Accuracy: 20.57%\n",
      "Epoch [2/5], Batch [255/625], Loss: 3.7604, Accuracy: 20.46%\n",
      "Epoch [2/5], Batch [260/625], Loss: 3.7475, Accuracy: 20.45%\n",
      "Epoch [2/5], Batch [265/625], Loss: 3.7945, Accuracy: 20.39%\n",
      "Epoch [2/5], Batch [270/625], Loss: 3.7540, Accuracy: 20.43%\n",
      "Epoch [2/5], Batch [275/625], Loss: 3.6758, Accuracy: 20.56%\n",
      "Epoch [2/5], Batch [280/625], Loss: 3.7372, Accuracy: 20.73%\n",
      "Epoch [2/5], Batch [285/625], Loss: 3.6950, Accuracy: 21.02%\n",
      "Epoch [2/5], Batch [290/625], Loss: 3.7435, Accuracy: 21.18%\n",
      "Epoch [2/5], Batch [295/625], Loss: 3.7771, Accuracy: 21.16%\n",
      "Epoch [2/5], Batch [300/625], Loss: 3.7807, Accuracy: 21.14%\n",
      "Epoch [2/5], Batch [305/625], Loss: 3.7080, Accuracy: 21.32%\n",
      "Epoch [2/5], Batch [310/625], Loss: 3.7193, Accuracy: 21.42%\n",
      "Epoch [2/5], Batch [315/625], Loss: 3.6717, Accuracy: 21.60%\n",
      "Epoch [2/5], Batch [320/625], Loss: 3.7604, Accuracy: 21.73%\n",
      "Epoch [2/5], Batch [325/625], Loss: 3.7733, Accuracy: 21.74%\n",
      "Epoch [2/5], Batch [330/625], Loss: 3.7092, Accuracy: 21.71%\n",
      "Epoch [2/5], Batch [335/625], Loss: 3.7117, Accuracy: 21.88%\n",
      "Epoch [2/5], Batch [340/625], Loss: 3.7953, Accuracy: 21.81%\n",
      "Epoch [2/5], Batch [345/625], Loss: 3.7121, Accuracy: 22.07%\n",
      "Epoch [2/5], Batch [350/625], Loss: 3.7357, Accuracy: 22.15%\n",
      "Epoch [2/5], Batch [355/625], Loss: 3.7186, Accuracy: 22.16%\n",
      "Epoch [2/5], Batch [360/625], Loss: 3.7296, Accuracy: 22.20%\n",
      "Epoch [2/5], Batch [365/625], Loss: 3.6672, Accuracy: 22.34%\n",
      "Epoch [2/5], Batch [370/625], Loss: 3.6761, Accuracy: 22.68%\n",
      "Epoch [2/5], Batch [375/625], Loss: 3.7925, Accuracy: 22.91%\n",
      "Epoch [2/5], Batch [380/625], Loss: 3.7176, Accuracy: 22.87%\n",
      "Epoch [2/5], Batch [385/625], Loss: 3.7830, Accuracy: 22.93%\n",
      "Epoch [2/5], Batch [390/625], Loss: 3.5905, Accuracy: 22.95%\n",
      "Epoch [2/5], Batch [395/625], Loss: 3.6462, Accuracy: 23.14%\n",
      "Epoch [2/5], Batch [400/625], Loss: 3.7507, Accuracy: 23.29%\n",
      "Epoch [2/5], Batch [405/625], Loss: 3.6911, Accuracy: 23.40%\n",
      "Epoch [2/5], Batch [410/625], Loss: 3.7364, Accuracy: 23.48%\n",
      "Epoch [2/5], Batch [415/625], Loss: 3.7443, Accuracy: 23.65%\n",
      "Epoch [2/5], Batch [420/625], Loss: 3.7667, Accuracy: 23.57%\n",
      "Epoch [2/5], Batch [425/625], Loss: 3.7390, Accuracy: 23.65%\n",
      "Epoch [2/5], Batch [430/625], Loss: 3.7186, Accuracy: 23.81%\n",
      "Epoch [2/5], Batch [435/625], Loss: 3.6980, Accuracy: 23.97%\n",
      "Epoch [2/5], Batch [440/625], Loss: 3.7166, Accuracy: 24.06%\n",
      "Epoch [2/5], Batch [445/625], Loss: 3.6713, Accuracy: 24.05%\n",
      "Epoch [2/5], Batch [450/625], Loss: 3.6710, Accuracy: 24.14%\n",
      "Epoch [2/5], Batch [455/625], Loss: 3.6428, Accuracy: 24.18%\n",
      "Epoch [2/5], Batch [460/625], Loss: 3.6676, Accuracy: 24.46%\n",
      "Epoch [2/5], Batch [465/625], Loss: 3.6787, Accuracy: 24.60%\n",
      "Epoch [2/5], Batch [470/625], Loss: 3.6459, Accuracy: 24.76%\n",
      "Epoch [2/5], Batch [475/625], Loss: 3.6325, Accuracy: 24.97%\n",
      "Epoch [2/5], Batch [480/625], Loss: 3.7955, Accuracy: 25.00%\n",
      "Epoch [2/5], Batch [485/625], Loss: 3.5954, Accuracy: 25.15%\n",
      "Epoch [2/5], Batch [490/625], Loss: 3.6683, Accuracy: 25.20%\n",
      "Epoch [2/5], Batch [495/625], Loss: 3.6600, Accuracy: 25.25%\n",
      "Epoch [2/5], Batch [500/625], Loss: 3.7021, Accuracy: 25.27%\n",
      "Epoch [2/5], Batch [505/625], Loss: 3.7049, Accuracy: 25.42%\n",
      "Epoch [2/5], Batch [510/625], Loss: 3.6503, Accuracy: 25.44%\n",
      "Epoch [2/5], Batch [515/625], Loss: 3.6715, Accuracy: 25.61%\n",
      "Epoch [2/5], Batch [520/625], Loss: 3.6822, Accuracy: 25.74%\n",
      "Epoch [2/5], Batch [525/625], Loss: 3.6599, Accuracy: 25.83%\n",
      "Epoch [2/5], Batch [530/625], Loss: 3.6513, Accuracy: 25.92%\n",
      "Epoch [2/5], Batch [535/625], Loss: 3.7056, Accuracy: 25.93%\n",
      "Epoch [2/5], Batch [540/625], Loss: 3.7739, Accuracy: 26.02%\n",
      "Epoch [2/5], Batch [545/625], Loss: 3.6601, Accuracy: 26.01%\n",
      "Epoch [2/5], Batch [550/625], Loss: 3.5804, Accuracy: 26.16%\n",
      "Epoch [2/5], Batch [555/625], Loss: 3.6013, Accuracy: 26.35%\n",
      "Epoch [2/5], Batch [560/625], Loss: 3.7086, Accuracy: 26.43%\n",
      "Epoch [2/5], Batch [565/625], Loss: 3.6525, Accuracy: 26.50%\n",
      "Epoch [2/5], Batch [570/625], Loss: 3.6847, Accuracy: 26.64%\n",
      "Epoch [2/5], Batch [575/625], Loss: 3.6194, Accuracy: 26.74%\n",
      "Epoch [2/5], Batch [580/625], Loss: 3.6624, Accuracy: 26.74%\n",
      "Epoch [2/5], Batch [585/625], Loss: 3.7217, Accuracy: 26.83%\n",
      "Epoch [2/5], Batch [590/625], Loss: 3.6722, Accuracy: 26.84%\n",
      "Epoch [2/5], Batch [595/625], Loss: 3.6275, Accuracy: 26.87%\n",
      "Epoch [2/5], Batch [600/625], Loss: 3.5882, Accuracy: 26.89%\n",
      "Epoch [2/5], Batch [605/625], Loss: 3.6012, Accuracy: 26.92%\n",
      "Epoch [2/5], Batch [610/625], Loss: 3.5737, Accuracy: 27.05%\n",
      "Epoch [2/5], Batch [615/625], Loss: 3.6268, Accuracy: 27.19%\n",
      "Epoch [2/5], Batch [620/625], Loss: 3.6622, Accuracy: 27.23%\n",
      "\n",
      "Epoch [2/5] Summary:\n",
      "  Average Loss: 3.7291\n",
      "  Accuracy: 27.28%\n",
      "--------------------------------------------------\n",
      "Epoch [3/5], Batch [0/625], Loss: 3.4776, Accuracy: 50.00%\n",
      "Epoch [3/5], Batch [5/625], Loss: 3.6831, Accuracy: 39.58%\n",
      "Epoch [3/5], Batch [10/625], Loss: 3.6086, Accuracy: 38.64%\n",
      "Epoch [3/5], Batch [15/625], Loss: 3.6249, Accuracy: 37.50%\n",
      "Epoch [3/5], Batch [20/625], Loss: 3.6393, Accuracy: 37.50%\n",
      "Epoch [3/5], Batch [25/625], Loss: 3.6341, Accuracy: 38.94%\n",
      "Epoch [3/5], Batch [30/625], Loss: 3.6322, Accuracy: 40.73%\n",
      "Epoch [3/5], Batch [35/625], Loss: 3.6161, Accuracy: 39.24%\n",
      "Epoch [3/5], Batch [40/625], Loss: 3.5310, Accuracy: 41.16%\n",
      "Epoch [3/5], Batch [45/625], Loss: 3.5476, Accuracy: 40.76%\n",
      "Epoch [3/5], Batch [50/625], Loss: 3.6253, Accuracy: 41.91%\n",
      "Epoch [3/5], Batch [55/625], Loss: 3.5090, Accuracy: 42.19%\n",
      "Epoch [3/5], Batch [60/625], Loss: 3.5586, Accuracy: 43.24%\n",
      "Epoch [3/5], Batch [65/625], Loss: 3.5178, Accuracy: 43.94%\n",
      "Epoch [3/5], Batch [70/625], Loss: 3.5598, Accuracy: 44.37%\n",
      "Epoch [3/5], Batch [75/625], Loss: 3.6463, Accuracy: 43.75%\n",
      "Epoch [3/5], Batch [80/625], Loss: 3.6235, Accuracy: 43.67%\n",
      "Epoch [3/5], Batch [85/625], Loss: 3.5544, Accuracy: 43.90%\n",
      "Epoch [3/5], Batch [90/625], Loss: 3.5291, Accuracy: 44.09%\n",
      "Epoch [3/5], Batch [95/625], Loss: 3.5282, Accuracy: 44.14%\n",
      "Epoch [3/5], Batch [100/625], Loss: 3.5516, Accuracy: 44.55%\n",
      "Epoch [3/5], Batch [105/625], Loss: 3.5604, Accuracy: 43.99%\n",
      "Epoch [3/5], Batch [110/625], Loss: 3.6444, Accuracy: 43.47%\n",
      "Epoch [3/5], Batch [115/625], Loss: 3.4614, Accuracy: 43.21%\n",
      "Epoch [3/5], Batch [120/625], Loss: 3.4521, Accuracy: 43.49%\n",
      "Epoch [3/5], Batch [125/625], Loss: 3.5474, Accuracy: 43.75%\n",
      "Epoch [3/5], Batch [130/625], Loss: 3.5111, Accuracy: 43.61%\n",
      "Epoch [3/5], Batch [135/625], Loss: 3.4876, Accuracy: 43.75%\n",
      "Epoch [3/5], Batch [140/625], Loss: 3.5186, Accuracy: 43.97%\n",
      "Epoch [3/5], Batch [145/625], Loss: 3.6266, Accuracy: 43.75%\n",
      "Epoch [3/5], Batch [150/625], Loss: 3.4988, Accuracy: 43.63%\n",
      "Epoch [3/5], Batch [155/625], Loss: 3.5940, Accuracy: 43.51%\n",
      "Epoch [3/5], Batch [160/625], Loss: 3.6535, Accuracy: 43.40%\n",
      "Epoch [3/5], Batch [165/625], Loss: 3.6041, Accuracy: 43.30%\n",
      "Epoch [3/5], Batch [170/625], Loss: 3.4928, Accuracy: 43.42%\n",
      "Epoch [3/5], Batch [175/625], Loss: 3.4209, Accuracy: 43.32%\n",
      "Epoch [3/5], Batch [180/625], Loss: 3.5018, Accuracy: 43.65%\n",
      "Epoch [3/5], Batch [185/625], Loss: 3.5275, Accuracy: 43.28%\n",
      "Epoch [3/5], Batch [190/625], Loss: 3.5200, Accuracy: 43.46%\n",
      "Epoch [3/5], Batch [195/625], Loss: 3.5676, Accuracy: 43.43%\n",
      "Epoch [3/5], Batch [200/625], Loss: 3.4657, Accuracy: 43.97%\n",
      "Epoch [3/5], Batch [205/625], Loss: 3.6731, Accuracy: 43.81%\n",
      "Epoch [3/5], Batch [210/625], Loss: 3.4835, Accuracy: 43.90%\n",
      "Epoch [3/5], Batch [215/625], Loss: 3.5606, Accuracy: 44.10%\n",
      "Epoch [3/5], Batch [220/625], Loss: 3.4820, Accuracy: 43.95%\n",
      "Epoch [3/5], Batch [225/625], Loss: 3.3766, Accuracy: 44.03%\n",
      "Epoch [3/5], Batch [230/625], Loss: 3.4727, Accuracy: 44.05%\n",
      "Epoch [3/5], Batch [235/625], Loss: 3.5626, Accuracy: 44.23%\n",
      "Epoch [3/5], Batch [240/625], Loss: 3.5026, Accuracy: 44.19%\n",
      "Epoch [3/5], Batch [245/625], Loss: 3.4701, Accuracy: 44.26%\n",
      "Epoch [3/5], Batch [250/625], Loss: 3.4738, Accuracy: 44.07%\n",
      "Epoch [3/5], Batch [255/625], Loss: 3.4163, Accuracy: 44.19%\n",
      "Epoch [3/5], Batch [260/625], Loss: 3.5619, Accuracy: 44.44%\n",
      "Epoch [3/5], Batch [265/625], Loss: 3.5741, Accuracy: 44.60%\n",
      "Epoch [3/5], Batch [270/625], Loss: 3.4394, Accuracy: 44.51%\n",
      "Epoch [3/5], Batch [275/625], Loss: 3.6474, Accuracy: 44.43%\n",
      "Epoch [3/5], Batch [280/625], Loss: 3.5374, Accuracy: 44.35%\n",
      "Epoch [3/5], Batch [285/625], Loss: 3.3909, Accuracy: 44.67%\n",
      "Epoch [3/5], Batch [290/625], Loss: 3.6118, Accuracy: 44.63%\n",
      "Epoch [3/5], Batch [295/625], Loss: 3.4255, Accuracy: 44.64%\n",
      "Epoch [3/5], Batch [300/625], Loss: 3.4935, Accuracy: 44.81%\n",
      "Epoch [3/5], Batch [305/625], Loss: 3.4385, Accuracy: 44.73%\n",
      "Epoch [3/5], Batch [310/625], Loss: 3.3743, Accuracy: 44.73%\n",
      "Epoch [3/5], Batch [315/625], Loss: 3.3468, Accuracy: 44.78%\n",
      "Epoch [3/5], Batch [320/625], Loss: 3.3759, Accuracy: 45.05%\n",
      "Epoch [3/5], Batch [325/625], Loss: 3.3811, Accuracy: 45.02%\n",
      "Epoch [3/5], Batch [330/625], Loss: 3.5333, Accuracy: 45.02%\n",
      "Epoch [3/5], Batch [335/625], Loss: 3.3392, Accuracy: 45.05%\n",
      "Epoch [3/5], Batch [340/625], Loss: 3.4444, Accuracy: 45.34%\n",
      "Epoch [3/5], Batch [345/625], Loss: 3.3521, Accuracy: 45.38%\n",
      "Epoch [3/5], Batch [350/625], Loss: 3.4379, Accuracy: 45.51%\n",
      "Epoch [3/5], Batch [355/625], Loss: 3.4428, Accuracy: 45.40%\n",
      "Epoch [3/5], Batch [360/625], Loss: 3.3976, Accuracy: 45.43%\n",
      "Epoch [3/5], Batch [365/625], Loss: 3.5117, Accuracy: 45.32%\n",
      "Epoch [3/5], Batch [370/625], Loss: 3.4131, Accuracy: 45.35%\n",
      "Epoch [3/5], Batch [375/625], Loss: 3.5361, Accuracy: 45.45%\n",
      "Epoch [3/5], Batch [380/625], Loss: 3.5558, Accuracy: 45.34%\n",
      "Epoch [3/5], Batch [385/625], Loss: 3.3308, Accuracy: 45.30%\n",
      "Epoch [3/5], Batch [390/625], Loss: 3.4170, Accuracy: 45.46%\n",
      "Epoch [3/5], Batch [395/625], Loss: 3.4274, Accuracy: 45.61%\n",
      "Epoch [3/5], Batch [400/625], Loss: 3.4187, Accuracy: 45.73%\n",
      "Epoch [3/5], Batch [405/625], Loss: 3.2953, Accuracy: 45.72%\n",
      "Epoch [3/5], Batch [410/625], Loss: 3.3352, Accuracy: 45.74%\n",
      "Epoch [3/5], Batch [415/625], Loss: 3.4152, Accuracy: 45.88%\n",
      "Epoch [3/5], Batch [420/625], Loss: 3.2872, Accuracy: 45.93%\n",
      "Epoch [3/5], Batch [425/625], Loss: 3.4660, Accuracy: 45.86%\n",
      "Epoch [3/5], Batch [430/625], Loss: 3.4131, Accuracy: 46.06%\n",
      "Epoch [3/5], Batch [435/625], Loss: 3.4166, Accuracy: 46.04%\n",
      "Epoch [3/5], Batch [440/625], Loss: 3.4064, Accuracy: 46.03%\n",
      "Epoch [3/5], Batch [445/625], Loss: 3.2428, Accuracy: 46.19%\n",
      "Epoch [3/5], Batch [450/625], Loss: 3.4431, Accuracy: 45.98%\n",
      "Epoch [3/5], Batch [455/625], Loss: 3.4521, Accuracy: 46.00%\n",
      "Epoch [3/5], Batch [460/625], Loss: 3.2114, Accuracy: 46.10%\n",
      "Epoch [3/5], Batch [465/625], Loss: 3.4131, Accuracy: 46.14%\n",
      "Epoch [3/5], Batch [470/625], Loss: 3.4397, Accuracy: 46.18%\n",
      "Epoch [3/5], Batch [475/625], Loss: 3.4420, Accuracy: 46.06%\n",
      "Epoch [3/5], Batch [480/625], Loss: 3.4756, Accuracy: 46.08%\n",
      "Epoch [3/5], Batch [485/625], Loss: 3.3410, Accuracy: 46.12%\n",
      "Epoch [3/5], Batch [490/625], Loss: 3.3492, Accuracy: 46.18%\n",
      "Epoch [3/5], Batch [495/625], Loss: 3.2800, Accuracy: 46.19%\n",
      "Epoch [3/5], Batch [500/625], Loss: 3.2378, Accuracy: 46.11%\n",
      "Epoch [3/5], Batch [505/625], Loss: 3.4546, Accuracy: 46.05%\n",
      "Epoch [3/5], Batch [510/625], Loss: 3.2476, Accuracy: 46.26%\n",
      "Epoch [3/5], Batch [515/625], Loss: 3.2345, Accuracy: 46.39%\n",
      "Epoch [3/5], Batch [520/625], Loss: 3.3565, Accuracy: 46.40%\n",
      "Epoch [3/5], Batch [525/625], Loss: 3.5198, Accuracy: 46.55%\n",
      "Epoch [3/5], Batch [530/625], Loss: 3.4235, Accuracy: 46.52%\n",
      "Epoch [3/5], Batch [535/625], Loss: 3.2200, Accuracy: 46.53%\n",
      "Epoch [3/5], Batch [540/625], Loss: 3.2856, Accuracy: 46.51%\n",
      "Epoch [3/5], Batch [545/625], Loss: 3.1523, Accuracy: 46.61%\n",
      "Epoch [3/5], Batch [550/625], Loss: 3.2621, Accuracy: 46.73%\n",
      "Epoch [3/5], Batch [555/625], Loss: 3.0163, Accuracy: 46.81%\n",
      "Epoch [3/5], Batch [560/625], Loss: 3.3351, Accuracy: 46.84%\n",
      "Epoch [3/5], Batch [565/625], Loss: 3.4253, Accuracy: 46.86%\n",
      "Epoch [3/5], Batch [570/625], Loss: 3.2940, Accuracy: 46.80%\n",
      "Epoch [3/5], Batch [575/625], Loss: 3.3644, Accuracy: 46.81%\n",
      "Epoch [3/5], Batch [580/625], Loss: 3.1934, Accuracy: 46.75%\n",
      "Epoch [3/5], Batch [585/625], Loss: 3.3564, Accuracy: 46.67%\n",
      "Epoch [3/5], Batch [590/625], Loss: 3.3624, Accuracy: 46.76%\n",
      "Epoch [3/5], Batch [595/625], Loss: 3.3856, Accuracy: 46.73%\n",
      "Epoch [3/5], Batch [600/625], Loss: 3.0653, Accuracy: 46.82%\n",
      "Epoch [3/5], Batch [605/625], Loss: 3.2709, Accuracy: 46.93%\n",
      "Epoch [3/5], Batch [610/625], Loss: 3.3076, Accuracy: 47.03%\n",
      "Epoch [3/5], Batch [615/625], Loss: 3.2924, Accuracy: 47.00%\n",
      "Epoch [3/5], Batch [620/625], Loss: 3.2887, Accuracy: 47.06%\n",
      "\n",
      "Epoch [3/5] Summary:\n",
      "  Average Loss: 3.4479\n",
      "  Accuracy: 47.00%\n",
      "--------------------------------------------------\n",
      "Epoch [4/5], Batch [0/625], Loss: 3.3841, Accuracy: 37.50%\n",
      "Epoch [4/5], Batch [5/625], Loss: 3.3487, Accuracy: 41.67%\n",
      "Epoch [4/5], Batch [10/625], Loss: 3.1741, Accuracy: 48.86%\n",
      "Epoch [4/5], Batch [15/625], Loss: 3.0578, Accuracy: 55.47%\n",
      "Epoch [4/5], Batch [20/625], Loss: 3.3413, Accuracy: 54.76%\n",
      "Epoch [4/5], Batch [25/625], Loss: 3.1846, Accuracy: 54.81%\n",
      "Epoch [4/5], Batch [30/625], Loss: 3.1567, Accuracy: 55.65%\n",
      "Epoch [4/5], Batch [35/625], Loss: 3.2883, Accuracy: 55.21%\n",
      "Epoch [4/5], Batch [40/625], Loss: 3.1986, Accuracy: 55.18%\n",
      "Epoch [4/5], Batch [45/625], Loss: 3.0736, Accuracy: 55.71%\n",
      "Epoch [4/5], Batch [50/625], Loss: 3.1779, Accuracy: 54.41%\n",
      "Epoch [4/5], Batch [55/625], Loss: 3.2034, Accuracy: 54.24%\n",
      "Epoch [4/5], Batch [60/625], Loss: 3.3329, Accuracy: 54.10%\n",
      "Epoch [4/5], Batch [65/625], Loss: 3.1647, Accuracy: 53.79%\n",
      "Epoch [4/5], Batch [70/625], Loss: 3.4004, Accuracy: 54.40%\n",
      "Epoch [4/5], Batch [75/625], Loss: 3.0744, Accuracy: 54.93%\n",
      "Epoch [4/5], Batch [80/625], Loss: 3.3584, Accuracy: 54.01%\n",
      "Epoch [4/5], Batch [85/625], Loss: 3.2831, Accuracy: 53.78%\n",
      "Epoch [4/5], Batch [90/625], Loss: 3.1149, Accuracy: 53.57%\n",
      "Epoch [4/5], Batch [95/625], Loss: 3.1676, Accuracy: 53.39%\n",
      "Epoch [4/5], Batch [100/625], Loss: 3.1204, Accuracy: 52.48%\n",
      "Epoch [4/5], Batch [105/625], Loss: 3.1054, Accuracy: 51.77%\n",
      "Epoch [4/5], Batch [110/625], Loss: 2.9303, Accuracy: 51.91%\n",
      "Epoch [4/5], Batch [115/625], Loss: 2.9808, Accuracy: 52.69%\n",
      "Epoch [4/5], Batch [120/625], Loss: 3.0704, Accuracy: 53.00%\n",
      "Epoch [4/5], Batch [125/625], Loss: 3.0460, Accuracy: 53.17%\n",
      "Epoch [4/5], Batch [130/625], Loss: 3.0465, Accuracy: 52.67%\n",
      "Epoch [4/5], Batch [135/625], Loss: 3.1068, Accuracy: 52.48%\n",
      "Epoch [4/5], Batch [140/625], Loss: 3.0540, Accuracy: 52.13%\n",
      "Epoch [4/5], Batch [145/625], Loss: 3.2658, Accuracy: 51.63%\n",
      "Epoch [4/5], Batch [150/625], Loss: 3.1671, Accuracy: 51.82%\n",
      "Epoch [4/5], Batch [155/625], Loss: 3.2076, Accuracy: 51.76%\n",
      "Epoch [4/5], Batch [160/625], Loss: 3.2302, Accuracy: 51.79%\n",
      "Epoch [4/5], Batch [165/625], Loss: 3.0700, Accuracy: 51.66%\n",
      "Epoch [4/5], Batch [170/625], Loss: 3.2233, Accuracy: 51.68%\n",
      "Epoch [4/5], Batch [175/625], Loss: 3.3471, Accuracy: 51.21%\n",
      "Epoch [4/5], Batch [180/625], Loss: 3.1773, Accuracy: 51.10%\n",
      "Epoch [4/5], Batch [185/625], Loss: 2.8674, Accuracy: 51.68%\n",
      "Epoch [4/5], Batch [190/625], Loss: 3.0534, Accuracy: 51.77%\n",
      "Epoch [4/5], Batch [195/625], Loss: 2.8954, Accuracy: 51.59%\n",
      "Epoch [4/5], Batch [200/625], Loss: 3.0424, Accuracy: 51.87%\n",
      "Epoch [4/5], Batch [205/625], Loss: 3.1131, Accuracy: 51.76%\n",
      "Epoch [4/5], Batch [210/625], Loss: 3.1652, Accuracy: 52.01%\n",
      "Epoch [4/5], Batch [215/625], Loss: 3.0853, Accuracy: 52.08%\n",
      "Epoch [4/5], Batch [220/625], Loss: 3.2208, Accuracy: 52.15%\n",
      "Epoch [4/5], Batch [225/625], Loss: 3.1217, Accuracy: 52.38%\n",
      "Epoch [4/5], Batch [230/625], Loss: 2.9270, Accuracy: 52.44%\n",
      "Epoch [4/5], Batch [235/625], Loss: 3.0191, Accuracy: 52.44%\n",
      "Epoch [4/5], Batch [240/625], Loss: 2.9513, Accuracy: 52.59%\n",
      "Epoch [4/5], Batch [245/625], Loss: 3.1205, Accuracy: 52.64%\n",
      "Epoch [4/5], Batch [250/625], Loss: 3.0125, Accuracy: 52.84%\n",
      "Epoch [4/5], Batch [255/625], Loss: 3.2288, Accuracy: 53.03%\n",
      "Epoch [4/5], Batch [260/625], Loss: 3.1974, Accuracy: 52.87%\n",
      "Epoch [4/5], Batch [265/625], Loss: 3.0413, Accuracy: 53.01%\n",
      "Epoch [4/5], Batch [270/625], Loss: 2.9036, Accuracy: 52.86%\n",
      "Epoch [4/5], Batch [275/625], Loss: 3.2807, Accuracy: 53.03%\n",
      "Epoch [4/5], Batch [280/625], Loss: 2.9652, Accuracy: 52.98%\n",
      "Epoch [4/5], Batch [285/625], Loss: 2.8012, Accuracy: 53.10%\n",
      "Epoch [4/5], Batch [290/625], Loss: 3.1044, Accuracy: 53.14%\n",
      "Epoch [4/5], Batch [295/625], Loss: 2.9946, Accuracy: 53.29%\n",
      "Epoch [4/5], Batch [300/625], Loss: 3.0480, Accuracy: 53.11%\n",
      "Epoch [4/5], Batch [305/625], Loss: 2.8450, Accuracy: 53.15%\n",
      "Epoch [4/5], Batch [310/625], Loss: 3.0600, Accuracy: 53.26%\n",
      "Epoch [4/5], Batch [315/625], Loss: 3.0153, Accuracy: 53.36%\n",
      "Epoch [4/5], Batch [320/625], Loss: 2.9795, Accuracy: 53.19%\n",
      "Epoch [4/5], Batch [325/625], Loss: 3.0393, Accuracy: 53.11%\n",
      "Epoch [4/5], Batch [330/625], Loss: 3.3106, Accuracy: 53.13%\n",
      "Epoch [4/5], Batch [335/625], Loss: 3.2762, Accuracy: 53.01%\n",
      "Epoch [4/5], Batch [340/625], Loss: 2.7161, Accuracy: 53.26%\n",
      "Epoch [4/5], Batch [345/625], Loss: 3.2769, Accuracy: 53.07%\n",
      "Epoch [4/5], Batch [350/625], Loss: 2.8984, Accuracy: 53.03%\n",
      "Epoch [4/5], Batch [355/625], Loss: 2.6786, Accuracy: 52.98%\n",
      "Epoch [4/5], Batch [360/625], Loss: 2.9047, Accuracy: 53.15%\n",
      "Epoch [4/5], Batch [365/625], Loss: 2.8704, Accuracy: 53.04%\n",
      "Epoch [4/5], Batch [370/625], Loss: 2.8917, Accuracy: 53.07%\n",
      "Epoch [4/5], Batch [375/625], Loss: 2.9813, Accuracy: 52.99%\n",
      "Epoch [4/5], Batch [380/625], Loss: 3.0089, Accuracy: 53.05%\n",
      "Epoch [4/5], Batch [385/625], Loss: 2.8899, Accuracy: 52.95%\n",
      "Epoch [4/5], Batch [390/625], Loss: 2.8114, Accuracy: 53.10%\n",
      "Epoch [4/5], Batch [395/625], Loss: 3.1865, Accuracy: 53.16%\n",
      "Epoch [4/5], Batch [400/625], Loss: 3.2140, Accuracy: 53.27%\n",
      "Epoch [4/5], Batch [405/625], Loss: 2.8810, Accuracy: 53.20%\n",
      "Epoch [4/5], Batch [410/625], Loss: 3.2147, Accuracy: 53.25%\n",
      "Epoch [4/5], Batch [415/625], Loss: 3.1799, Accuracy: 53.22%\n",
      "Epoch [4/5], Batch [420/625], Loss: 3.1359, Accuracy: 53.06%\n",
      "Epoch [4/5], Batch [425/625], Loss: 2.9382, Accuracy: 53.05%\n",
      "Epoch [4/5], Batch [430/625], Loss: 3.0827, Accuracy: 52.99%\n",
      "Epoch [4/5], Batch [435/625], Loss: 2.6275, Accuracy: 53.24%\n",
      "Epoch [4/5], Batch [440/625], Loss: 2.9761, Accuracy: 53.09%\n",
      "Epoch [4/5], Batch [445/625], Loss: 2.6139, Accuracy: 53.03%\n",
      "Epoch [4/5], Batch [450/625], Loss: 2.8674, Accuracy: 53.02%\n",
      "Epoch [4/5], Batch [455/625], Loss: 3.0422, Accuracy: 53.12%\n",
      "Epoch [4/5], Batch [460/625], Loss: 2.7575, Accuracy: 53.36%\n",
      "Epoch [4/5], Batch [465/625], Loss: 3.2130, Accuracy: 53.51%\n",
      "Epoch [4/5], Batch [470/625], Loss: 3.1023, Accuracy: 53.64%\n",
      "Epoch [4/5], Batch [475/625], Loss: 3.1810, Accuracy: 53.81%\n",
      "Epoch [4/5], Batch [480/625], Loss: 2.9840, Accuracy: 53.79%\n",
      "Epoch [4/5], Batch [485/625], Loss: 2.7345, Accuracy: 53.73%\n",
      "Epoch [4/5], Batch [490/625], Loss: 2.7557, Accuracy: 53.87%\n",
      "Epoch [4/5], Batch [495/625], Loss: 2.8995, Accuracy: 53.86%\n",
      "Epoch [4/5], Batch [500/625], Loss: 2.8842, Accuracy: 53.89%\n",
      "Epoch [4/5], Batch [505/625], Loss: 2.6341, Accuracy: 53.95%\n",
      "Epoch [4/5], Batch [510/625], Loss: 3.0360, Accuracy: 53.89%\n",
      "Epoch [4/5], Batch [515/625], Loss: 2.6496, Accuracy: 53.90%\n",
      "Epoch [4/5], Batch [520/625], Loss: 2.6824, Accuracy: 53.84%\n",
      "Epoch [4/5], Batch [525/625], Loss: 2.7592, Accuracy: 53.75%\n",
      "Epoch [4/5], Batch [530/625], Loss: 2.9284, Accuracy: 53.74%\n",
      "Epoch [4/5], Batch [535/625], Loss: 3.0570, Accuracy: 53.85%\n",
      "Epoch [4/5], Batch [540/625], Loss: 2.8066, Accuracy: 53.84%\n",
      "Epoch [4/5], Batch [545/625], Loss: 2.7249, Accuracy: 53.89%\n",
      "Epoch [4/5], Batch [550/625], Loss: 2.7890, Accuracy: 53.90%\n",
      "Epoch [4/5], Batch [555/625], Loss: 3.0555, Accuracy: 53.96%\n",
      "Epoch [4/5], Batch [560/625], Loss: 2.9695, Accuracy: 54.03%\n",
      "Epoch [4/5], Batch [565/625], Loss: 2.7084, Accuracy: 54.09%\n",
      "Epoch [4/5], Batch [570/625], Loss: 3.1998, Accuracy: 54.05%\n",
      "Epoch [4/5], Batch [575/625], Loss: 2.8662, Accuracy: 54.19%\n",
      "Epoch [4/5], Batch [580/625], Loss: 2.2307, Accuracy: 54.17%\n",
      "Epoch [4/5], Batch [585/625], Loss: 2.8544, Accuracy: 54.22%\n",
      "Epoch [4/5], Batch [590/625], Loss: 3.1014, Accuracy: 54.27%\n",
      "Epoch [4/5], Batch [595/625], Loss: 2.6393, Accuracy: 54.17%\n",
      "Epoch [4/5], Batch [600/625], Loss: 2.4934, Accuracy: 54.20%\n",
      "Epoch [4/5], Batch [605/625], Loss: 3.0824, Accuracy: 54.19%\n",
      "Epoch [4/5], Batch [610/625], Loss: 2.7582, Accuracy: 54.21%\n",
      "Epoch [4/5], Batch [615/625], Loss: 2.7646, Accuracy: 54.22%\n",
      "Epoch [4/5], Batch [620/625], Loss: 2.6615, Accuracy: 54.25%\n",
      "\n",
      "Epoch [4/5] Summary:\n",
      "  Average Loss: 3.0130\n",
      "  Accuracy: 54.22%\n",
      "--------------------------------------------------\n",
      "Epoch [5/5], Batch [0/625], Loss: 2.7115, Accuracy: 62.50%\n",
      "Epoch [5/5], Batch [5/625], Loss: 2.5514, Accuracy: 52.08%\n",
      "Epoch [5/5], Batch [10/625], Loss: 2.4516, Accuracy: 62.50%\n",
      "Epoch [5/5], Batch [15/625], Loss: 2.6869, Accuracy: 63.28%\n",
      "Epoch [5/5], Batch [20/625], Loss: 2.7172, Accuracy: 63.69%\n",
      "Epoch [5/5], Batch [25/625], Loss: 2.7505, Accuracy: 62.98%\n",
      "Epoch [5/5], Batch [30/625], Loss: 2.5243, Accuracy: 62.50%\n",
      "Epoch [5/5], Batch [35/625], Loss: 2.9765, Accuracy: 60.07%\n",
      "Epoch [5/5], Batch [40/625], Loss: 2.6085, Accuracy: 59.45%\n",
      "Epoch [5/5], Batch [45/625], Loss: 2.6584, Accuracy: 60.05%\n",
      "Epoch [5/5], Batch [50/625], Loss: 2.6849, Accuracy: 60.29%\n",
      "Epoch [5/5], Batch [55/625], Loss: 2.9136, Accuracy: 60.94%\n",
      "Epoch [5/5], Batch [60/625], Loss: 2.6504, Accuracy: 61.27%\n",
      "Epoch [5/5], Batch [65/625], Loss: 2.5124, Accuracy: 61.17%\n",
      "Epoch [5/5], Batch [70/625], Loss: 2.7828, Accuracy: 61.09%\n",
      "Epoch [5/5], Batch [75/625], Loss: 2.2368, Accuracy: 60.86%\n",
      "Epoch [5/5], Batch [80/625], Loss: 2.8094, Accuracy: 60.65%\n",
      "Epoch [5/5], Batch [85/625], Loss: 2.8419, Accuracy: 60.03%\n",
      "Epoch [5/5], Batch [90/625], Loss: 2.5734, Accuracy: 59.75%\n",
      "Epoch [5/5], Batch [95/625], Loss: 2.7091, Accuracy: 58.85%\n",
      "Epoch [5/5], Batch [100/625], Loss: 2.4674, Accuracy: 58.42%\n",
      "Epoch [5/5], Batch [105/625], Loss: 2.4140, Accuracy: 58.49%\n",
      "Epoch [5/5], Batch [110/625], Loss: 2.9771, Accuracy: 57.77%\n",
      "Epoch [5/5], Batch [115/625], Loss: 2.5627, Accuracy: 57.87%\n",
      "Epoch [5/5], Batch [120/625], Loss: 2.3041, Accuracy: 57.85%\n",
      "Epoch [5/5], Batch [125/625], Loss: 2.7068, Accuracy: 57.64%\n",
      "Epoch [5/5], Batch [130/625], Loss: 2.9580, Accuracy: 57.63%\n",
      "Epoch [5/5], Batch [135/625], Loss: 2.6518, Accuracy: 57.72%\n",
      "Epoch [5/5], Batch [140/625], Loss: 2.5381, Accuracy: 57.54%\n",
      "Epoch [5/5], Batch [145/625], Loss: 2.3239, Accuracy: 57.88%\n",
      "Epoch [5/5], Batch [150/625], Loss: 2.7421, Accuracy: 57.70%\n",
      "Epoch [5/5], Batch [155/625], Loss: 2.9121, Accuracy: 57.77%\n",
      "Epoch [5/5], Batch [160/625], Loss: 2.5436, Accuracy: 57.84%\n",
      "Epoch [5/5], Batch [165/625], Loss: 2.8590, Accuracy: 58.06%\n",
      "Epoch [5/5], Batch [170/625], Loss: 2.9392, Accuracy: 57.97%\n",
      "Epoch [5/5], Batch [175/625], Loss: 2.5839, Accuracy: 57.95%\n",
      "Epoch [5/5], Batch [180/625], Loss: 2.4975, Accuracy: 57.53%\n",
      "Epoch [5/5], Batch [185/625], Loss: 2.7121, Accuracy: 57.19%\n",
      "Epoch [5/5], Batch [190/625], Loss: 2.5197, Accuracy: 57.46%\n",
      "Epoch [5/5], Batch [195/625], Loss: 3.0316, Accuracy: 57.46%\n",
      "Epoch [5/5], Batch [200/625], Loss: 2.4421, Accuracy: 57.52%\n",
      "Epoch [5/5], Batch [205/625], Loss: 2.6587, Accuracy: 57.16%\n",
      "Epoch [5/5], Batch [210/625], Loss: 2.6918, Accuracy: 57.29%\n",
      "Epoch [5/5], Batch [215/625], Loss: 2.3283, Accuracy: 57.41%\n",
      "Epoch [5/5], Batch [220/625], Loss: 2.8742, Accuracy: 57.64%\n",
      "Epoch [5/5], Batch [225/625], Loss: 2.7330, Accuracy: 57.41%\n",
      "Epoch [5/5], Batch [230/625], Loss: 2.5679, Accuracy: 57.52%\n",
      "Epoch [5/5], Batch [235/625], Loss: 3.2152, Accuracy: 57.68%\n",
      "Epoch [5/5], Batch [240/625], Loss: 2.6312, Accuracy: 57.68%\n",
      "Epoch [5/5], Batch [245/625], Loss: 2.4503, Accuracy: 57.67%\n",
      "Epoch [5/5], Batch [250/625], Loss: 2.7025, Accuracy: 57.62%\n",
      "Epoch [5/5], Batch [255/625], Loss: 2.2730, Accuracy: 57.57%\n",
      "Epoch [5/5], Batch [260/625], Loss: 2.5139, Accuracy: 57.76%\n",
      "Epoch [5/5], Batch [265/625], Loss: 2.6669, Accuracy: 57.66%\n",
      "Epoch [5/5], Batch [270/625], Loss: 2.8026, Accuracy: 57.75%\n",
      "Epoch [5/5], Batch [275/625], Loss: 2.3942, Accuracy: 57.79%\n",
      "Epoch [5/5], Batch [280/625], Loss: 2.7944, Accuracy: 58.01%\n",
      "Epoch [5/5], Batch [285/625], Loss: 2.1849, Accuracy: 58.00%\n",
      "Epoch [5/5], Batch [290/625], Loss: 2.4784, Accuracy: 57.90%\n",
      "Epoch [5/5], Batch [295/625], Loss: 2.5674, Accuracy: 57.81%\n",
      "Epoch [5/5], Batch [300/625], Loss: 2.6535, Accuracy: 57.81%\n",
      "Epoch [5/5], Batch [305/625], Loss: 2.2261, Accuracy: 57.80%\n",
      "Epoch [5/5], Batch [310/625], Loss: 2.4974, Accuracy: 57.76%\n",
      "Epoch [5/5], Batch [315/625], Loss: 2.4081, Accuracy: 57.67%\n",
      "Epoch [5/5], Batch [320/625], Loss: 2.4014, Accuracy: 57.48%\n",
      "Epoch [5/5], Batch [325/625], Loss: 2.5398, Accuracy: 57.59%\n",
      "Epoch [5/5], Batch [330/625], Loss: 2.9587, Accuracy: 57.29%\n",
      "Epoch [5/5], Batch [335/625], Loss: 2.6907, Accuracy: 57.44%\n",
      "Epoch [5/5], Batch [340/625], Loss: 2.5530, Accuracy: 57.40%\n",
      "Epoch [5/5], Batch [345/625], Loss: 2.5661, Accuracy: 57.37%\n",
      "Epoch [5/5], Batch [350/625], Loss: 2.6187, Accuracy: 57.41%\n",
      "Epoch [5/5], Batch [355/625], Loss: 2.8523, Accuracy: 57.51%\n",
      "Epoch [5/5], Batch [360/625], Loss: 2.4714, Accuracy: 57.62%\n",
      "Epoch [5/5], Batch [365/625], Loss: 2.4638, Accuracy: 57.72%\n",
      "Epoch [5/5], Batch [370/625], Loss: 2.1043, Accuracy: 57.99%\n",
      "Epoch [5/5], Batch [375/625], Loss: 2.5332, Accuracy: 58.01%\n",
      "Epoch [5/5], Batch [380/625], Loss: 2.8704, Accuracy: 58.14%\n",
      "Epoch [5/5], Batch [385/625], Loss: 2.3791, Accuracy: 58.26%\n",
      "Epoch [5/5], Batch [390/625], Loss: 2.6520, Accuracy: 58.22%\n",
      "Epoch [5/5], Batch [395/625], Loss: 2.0393, Accuracy: 58.14%\n",
      "Epoch [5/5], Batch [400/625], Loss: 2.3328, Accuracy: 58.32%\n",
      "Epoch [5/5], Batch [405/625], Loss: 2.9566, Accuracy: 58.19%\n",
      "Epoch [5/5], Batch [410/625], Loss: 2.4168, Accuracy: 58.18%\n",
      "Epoch [5/5], Batch [415/625], Loss: 2.6104, Accuracy: 58.11%\n",
      "Epoch [5/5], Batch [420/625], Loss: 2.1018, Accuracy: 58.19%\n",
      "Epoch [5/5], Batch [425/625], Loss: 2.7241, Accuracy: 58.22%\n",
      "Epoch [5/5], Batch [430/625], Loss: 1.9491, Accuracy: 58.32%\n",
      "Epoch [5/5], Batch [435/625], Loss: 2.3941, Accuracy: 58.43%\n",
      "Epoch [5/5], Batch [440/625], Loss: 2.3294, Accuracy: 58.42%\n",
      "Epoch [5/5], Batch [445/625], Loss: 2.3509, Accuracy: 58.41%\n",
      "Epoch [5/5], Batch [450/625], Loss: 2.3084, Accuracy: 58.37%\n",
      "Epoch [5/5], Batch [455/625], Loss: 2.5420, Accuracy: 58.33%\n",
      "Epoch [5/5], Batch [460/625], Loss: 2.5762, Accuracy: 58.32%\n",
      "Epoch [5/5], Batch [465/625], Loss: 2.2608, Accuracy: 58.34%\n",
      "Epoch [5/5], Batch [470/625], Loss: 2.2199, Accuracy: 58.49%\n",
      "Epoch [5/5], Batch [475/625], Loss: 2.4560, Accuracy: 58.43%\n",
      "Epoch [5/5], Batch [480/625], Loss: 2.7986, Accuracy: 58.32%\n",
      "Epoch [5/5], Batch [485/625], Loss: 2.4393, Accuracy: 58.31%\n",
      "Epoch [5/5], Batch [490/625], Loss: 2.5398, Accuracy: 58.15%\n",
      "Epoch [5/5], Batch [495/625], Loss: 2.1590, Accuracy: 58.22%\n",
      "Epoch [5/5], Batch [500/625], Loss: 2.5983, Accuracy: 58.21%\n",
      "Epoch [5/5], Batch [505/625], Loss: 2.3898, Accuracy: 58.28%\n",
      "Epoch [5/5], Batch [510/625], Loss: 2.2953, Accuracy: 58.41%\n",
      "Epoch [5/5], Batch [515/625], Loss: 2.2962, Accuracy: 58.43%\n",
      "Epoch [5/5], Batch [520/625], Loss: 2.4587, Accuracy: 58.47%\n",
      "Epoch [5/5], Batch [525/625], Loss: 2.5436, Accuracy: 58.44%\n",
      "Epoch [5/5], Batch [530/625], Loss: 2.4740, Accuracy: 58.47%\n",
      "Epoch [5/5], Batch [535/625], Loss: 1.8703, Accuracy: 58.54%\n",
      "Epoch [5/5], Batch [540/625], Loss: 2.3207, Accuracy: 58.57%\n",
      "Epoch [5/5], Batch [545/625], Loss: 2.4593, Accuracy: 58.56%\n",
      "Epoch [5/5], Batch [550/625], Loss: 2.1645, Accuracy: 58.60%\n",
      "Epoch [5/5], Batch [555/625], Loss: 2.0156, Accuracy: 58.77%\n",
      "Epoch [5/5], Batch [560/625], Loss: 2.2157, Accuracy: 58.73%\n",
      "Epoch [5/5], Batch [565/625], Loss: 2.1425, Accuracy: 58.72%\n",
      "Epoch [5/5], Batch [570/625], Loss: 2.7016, Accuracy: 58.76%\n",
      "Epoch [5/5], Batch [575/625], Loss: 2.3347, Accuracy: 58.81%\n",
      "Epoch [5/5], Batch [580/625], Loss: 2.0608, Accuracy: 58.82%\n",
      "Epoch [5/5], Batch [585/625], Loss: 1.6799, Accuracy: 58.87%\n",
      "Epoch [5/5], Batch [590/625], Loss: 2.2300, Accuracy: 58.84%\n",
      "Epoch [5/5], Batch [595/625], Loss: 2.4627, Accuracy: 58.85%\n",
      "Epoch [5/5], Batch [600/625], Loss: 2.1275, Accuracy: 58.96%\n",
      "Epoch [5/5], Batch [605/625], Loss: 1.8268, Accuracy: 58.89%\n",
      "Epoch [5/5], Batch [610/625], Loss: 2.2245, Accuracy: 58.94%\n",
      "Epoch [5/5], Batch [615/625], Loss: 2.2788, Accuracy: 58.99%\n",
      "Epoch [5/5], Batch [620/625], Loss: 2.1921, Accuracy: 59.06%\n",
      "\n",
      "Epoch [5/5] Summary:\n",
      "  Average Loss: 2.5081\n",
      "  Accuracy: 59.14%\n",
      "--------------------------------------------------\n",
      "\n",
      "Model saved successfully at classifier_finetuned\n",
      "Files saved:\n",
      "  - Model weights: classifier_finetuned/pytorch_model.bin\n",
      "  - Model config: classifier_finetuned/config.json\n",
      "  - Processor config: classifier_finetuned/preprocessor_config.json\n",
      "  - Label mappings: classifier_finetuned/label_mappings.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def train():\n",
    "    cfg = ModelConfig()\n",
    "    print(f\"Using device: {cfg.device}\")\n",
    "    \n",
    "    try:\n",
    "        temp_processor = AutoImageProcessor.from_pretrained(cfg.model_name)\n",
    "        dataset = AmazonDataset(cfg.input_dir, temp_processor, cfg.image_size)\n",
    "        num_labels = len(dataset.label2id)\n",
    "        \n",
    "        config = AutoConfig.from_pretrained(cfg.model_name)\n",
    "        config.num_labels = num_labels\n",
    "        config.id2label = dataset.id2label\n",
    "        config.label2id = dataset.label2id\n",
    "        \n",
    "        model = AutoModelForImageClassification.from_pretrained(\n",
    "            cfg.model_name, \n",
    "            config=config,\n",
    "            ignore_mismatched_sizes=True \n",
    "        )\n",
    "        \n",
    "        processor = AutoImageProcessor.from_pretrained(cfg.model_name)\n",
    "        model.to(cfg.device)\n",
    "        \n",
    "        dataloader = DataLoader(\n",
    "            dataset, \n",
    "            batch_size=cfg.train_batch_size, \n",
    "            shuffle=True, \n",
    "            collate_fn=collate_fn,\n",
    "            num_workers=0\n",
    "        )\n",
    "\n",
    "        optimizer = AdamW(model.parameters(), lr=cfg.learning_rate, weight_decay=0.01)\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        print(f\"Starting training for {cfg.num_epochs} epochs...\")\n",
    "        print(f\"Total batches per epoch: {len(dataloader)}\")\n",
    "        \n",
    "        for epoch in range(cfg.num_epochs):\n",
    "            total_loss = 0\n",
    "            correct_predictions = 0\n",
    "            total_predictions = 0\n",
    "            \n",
    "            for batch_idx, batch in enumerate(dataloader):\n",
    "                try:\n",
    "                    pixel_values = batch[\"pixel_values\"].to(cfg.device)\n",
    "                    labels = batch[\"labels\"].to(cfg.device)\n",
    "\n",
    "                    outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "                    loss = outputs.loss\n",
    "                    logits = outputs.logits\n",
    "\n",
    "                    predictions = torch.argmax(logits, dim=-1)\n",
    "                    correct_predictions += (predictions == labels).sum().item()\n",
    "                    total_predictions += labels.size(0)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    total_loss += loss.item()\n",
    "                    \n",
    "                    if batch_idx % 5 == 0:\n",
    "                        accuracy = correct_predictions / total_predictions * 100\n",
    "                        print(f\"Epoch [{epoch+1}/{cfg.num_epochs}], \"\n",
    "                              f\"Batch [{batch_idx}/{len(dataloader)}], \"\n",
    "                              f\"Loss: {loss.item():.4f}, \"\n",
    "                              f\"Accuracy: {accuracy:.2f}%\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error in batch {batch_idx}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            avg_loss = total_loss / len(dataloader)\n",
    "            epoch_accuracy = correct_predictions / total_predictions * 100\n",
    "            print(f\"\\nEpoch [{epoch+1}/{cfg.num_epochs}] Summary:\")\n",
    "            print(f\"  Average Loss: {avg_loss:.4f}\")\n",
    "            print(f\"  Accuracy: {epoch_accuracy:.2f}%\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "        os.makedirs(cfg.output_dir, exist_ok=True)\n",
    "        model.save_pretrained(cfg.output_dir)\n",
    "        processor.save_pretrained(cfg.output_dir)\n",
    "        \n",
    "        import json\n",
    "        with open(os.path.join(cfg.output_dir, 'label_mappings.json'), 'w') as f:\n",
    "            json.dump({\n",
    "                'label2id': dataset.label2id,\n",
    "                'id2label': dataset.id2label\n",
    "            }, f, indent=2)\n",
    "        \n",
    "        print(f\"\\nModel saved successfully at {cfg.output_dir}\")\n",
    "        print(\"Files saved:\")\n",
    "        print(f\"  - Model weights: {cfg.output_dir}/pytorch_model.bin\")\n",
    "        print(f\"  - Model config: {cfg.output_dir}/config.json\")\n",
    "        print(f\"  - Processor config: {cfg.output_dir}/preprocessor_config.json\")\n",
    "        print(f\"  - Label mappings: {cfg.output_dir}/label_mappings.json\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "       \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "def test_model():\n",
    "    cfg = ModelConfig()\n",
    "    \n",
    "    try:\n",
    "        model = AutoModelForImageClassification.from_pretrained(cfg.output_dir)\n",
    "        processor = AutoImageProcessor.from_pretrained(cfg.output_dir)\n",
    "        \n",
    "        import json\n",
    "        with open(os.path.join(cfg.output_dir, 'label_mappings.json'), 'r') as f:\n",
    "            mappings = json.load(f)\n",
    "            id2label = {int(k): v for k, v in mappings['id2label'].items()}\n",
    "        \n",
    "        model.eval()\n",
    "        model.to(cfg.device)\n",
    "        \n",
    "        print(\"Model loaded successfully!\")\n",
    "        print(\"Available classes:\", list(id2label.values()))\n",
    "        \n",
    "        def predict_image(image_path):\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            inputs = processor(image, return_tensors=\"pt\").to(cfg.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "                predicted_class_id = predictions.argmax().item()\n",
    "                confidence = predictions[0][predicted_class_id].item()\n",
    "                \n",
    "            return id2label[predicted_class_id], confidence\n",
    "        \n",
    "        return predict_image\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb7c7bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
