{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8a15b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, AutoConfig\n",
    "from torch.optim import AdamW\n",
    "import torchvision.transforms as transforms\n",
    "import json\n",
    "import numpy as np\n",
    "from typing import Tuple, Dict, List\n",
    "import random\n",
    "\n",
    "@dataclass\n",
    "class ModelConfig:\n",
    "    input_dir: str = \"images_for_finetuning\"\n",
    "    output_dir: str = \"classifier_finetuned\"\n",
    "    model_name: str = \"microsoft/resnet-50\"  \n",
    "    train_batch_size: int = 8\n",
    "    eval_batch_size: int = 4\n",
    "    num_epochs: int = 20\n",
    "    learning_rate: float = 1e-4\n",
    "    image_size: int = 224\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    train_ratio: float = 0.7\n",
    "    val_ratio: float = 0.2\n",
    "    test_ratio: float = 0.1\n",
    "    use_augmentation: bool = True\n",
    "    rotation_degrees: int = 15\n",
    "    brightness: float = 0.2\n",
    "    contrast: float = 0.2\n",
    "    saturation: float = 0.2\n",
    "    hue: float = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51af6e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazonDataset(Dataset):\n",
    "    def __init__(self, root_dir, processor, image_size=224, split='train', augment=True):\n",
    "        self.root_dir = root_dir\n",
    "        self.processor = processor\n",
    "        self.image_size = image_size\n",
    "        self.split = split\n",
    "        self.augment = augment and (split == 'train')\n",
    "        self.samples = []\n",
    "\n",
    "        if not os.path.exists(root_dir):\n",
    "            raise FileNotFoundError(f\"Directory '{root_dir}' not found. Please create the directory and add your image data.\")\n",
    "\n",
    "        class_dirs = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "        if not class_dirs:\n",
    "            raise ValueError(f\"No class directories found in '{root_dir}'\")\n",
    "\n",
    "        all_samples = []\n",
    "        for label in class_dirs:\n",
    "            class_dir = os.path.join(root_dir, label)\n",
    "            for img_file in os.listdir(class_dir):\n",
    "                if img_file.lower().endswith(('.jpeg', '.jpg', '.png', '.bmp', '.tiff')):\n",
    "                    all_samples.append((os.path.join(class_dir, img_file), label))\n",
    "\n",
    "        if not all_samples:\n",
    "            raise ValueError(f\"No images found in '{root_dir}'. Please check your directory structure.\")\n",
    "\n",
    "        self.label2id = {label: idx for idx, label in enumerate(sorted(class_dirs))}\n",
    "        self.id2label = {v: k for k, v in self.label2id.items()}\n",
    "        \n",
    "        self.samples = self._split_data(all_samples, split)\n",
    "        \n",
    "        if self.augment:\n",
    "            self.augmentation = transforms.Compose([\n",
    "                transforms.RandomRotation(degrees=15),\n",
    "                transforms.ColorJitter(\n",
    "                    brightness=0.2,\n",
    "                    contrast=0.2,\n",
    "                    saturation=0.2,\n",
    "                    hue=0.1\n",
    "                ),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomResizedCrop(size=(image_size, image_size), scale=(0.8, 1.0)),\n",
    "            ])\n",
    "        else:\n",
    "            self.augmentation = transforms.Compose([\n",
    "                transforms.Resize((image_size, image_size)),\n",
    "            ])\n",
    "        \n",
    "        print(f\"Split '{split}': Found {len(self.samples)} images across {len(self.label2id)} classes\")\n",
    "        if split == 'train':  \n",
    "            for label, idx in self.label2id.items():\n",
    "                count = sum(1 for _, l in self.samples if l == label)\n",
    "                print(f\"  {label}: {count} images (id: {idx})\")\n",
    "\n",
    "    def _split_data(self, all_samples: List[Tuple[str, str]], split: str) -> List[Tuple[str, str]]:\n",
    "        class_samples = {}\n",
    "        for sample in all_samples:\n",
    "            label = sample[1]\n",
    "            if label not in class_samples:\n",
    "                class_samples[label] = []\n",
    "            class_samples[label].append(sample)\n",
    "        \n",
    "        split_samples = []\n",
    "        for label, samples in class_samples.items():\n",
    "            random.shuffle(samples)\n",
    "            \n",
    "            n_samples = len(samples)\n",
    "            train_end = int(n_samples * 0.7)  \n",
    "            val_end = int(n_samples * 0.9)    \n",
    "            \n",
    "            if split == 'train':\n",
    "                split_samples.extend(samples[:train_end])\n",
    "            elif split == 'val':\n",
    "                split_samples.extend(samples[train_end:val_end])\n",
    "            elif split == 'test':\n",
    "                split_samples.extend(samples[val_end:])\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown split: {split}\")\n",
    "        \n",
    "        return split_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            \n",
    "            if self.augment:\n",
    "                image = self.augmentation(image)\n",
    "            else:\n",
    "                image = transforms.Resize((self.image_size, self.image_size))(image)\n",
    "            \n",
    "            inputs = self.processor(image, return_tensors=\"pt\")\n",
    "            \n",
    "            return {\n",
    "                'pixel_values': inputs['pixel_values'].squeeze(0), \n",
    "                'labels': torch.tensor(self.label2id[label], dtype=torch.long)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {img_path}: {e}\")\n",
    "            raise\n",
    "\n",
    "def collate_fn(batch):\n",
    "    pixel_values = torch.stack([item['pixel_values'] for item in batch])\n",
    "    labels = torch.stack([item['labels'] for item in batch])\n",
    "    \n",
    "    return {\n",
    "        'pixel_values': pixel_values,\n",
    "        'labels': labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9218568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device, split_name=\"Validation\"):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            pixel_values = batch[\"pixel_values\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            correct_predictions += (predictions == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct_predictions / total_predictions * 100\n",
    "    \n",
    "    print(f\"{split_name} - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abb7c7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Creating datasets...\n",
      "Split 'train': Found 3500 images across 50 classes\n",
      "  AirPods: 70 images (id: 0)\n",
      "  Android_phone: 70 images (id: 1)\n",
      "  CD_player: 70 images (id: 2)\n",
      "  DVD_player: 70 images (id: 3)\n",
      "  Lightning_cable: 70 images (id: 4)\n",
      "  TV_remote_control: 70 images (id: 5)\n",
      "  USB-C_cable: 70 images (id: 6)\n",
      "  air_freshener_dispenser: 70 images (id: 7)\n",
      "  air_fryer: 70 images (id: 8)\n",
      "  blood_pressure_monitor: 70 images (id: 9)\n",
      "  bluetooth_speaker: 70 images (id: 10)\n",
      "  calculator: 70 images (id: 11)\n",
      "  car_charger: 70 images (id: 12)\n",
      "  computer_mouse: 70 images (id: 13)\n",
      "  digital_thermometer: 70 images (id: 14)\n",
      "  electric_fan: 70 images (id: 15)\n",
      "  electric_kettle: 70 images (id: 16)\n",
      "  electric_toothbrush: 70 images (id: 17)\n",
      "  fitness_tracker: 70 images (id: 18)\n",
      "  food_scale: 70 images (id: 19)\n",
      "  hair_dryer: 70 images (id: 20)\n",
      "  hand_mixer: 70 images (id: 21)\n",
      "  headphones: 70 images (id: 22)\n",
      "  iPhone: 70 images (id: 23)\n",
      "  iPhone_charger: 70 images (id: 24)\n",
      "  juicer: 70 images (id: 25)\n",
      "  kitchen_blender: 70 images (id: 26)\n",
      "  laptop_charger: 70 images (id: 27)\n",
      "  laptop_computer: 70 images (id: 28)\n",
      "  mechanical_keyboard: 70 images (id: 29)\n",
      "  micro_USB_cable: 70 images (id: 30)\n",
      "  microwave: 70 images (id: 31)\n",
      "  nail_clipper: 70 images (id: 32)\n",
      "  phone_charger: 70 images (id: 33)\n",
      "  power_bank: 70 images (id: 34)\n",
      "  printer: 70 images (id: 35)\n",
      "  scanner: 70 images (id: 36)\n",
      "  security_camera: 70 images (id: 37)\n",
      "  smart_light_bulb: 70 images (id: 38)\n",
      "  smart_speaker: 70 images (id: 39)\n",
      "  smartwatch: 70 images (id: 40)\n",
      "  soundbar: 70 images (id: 41)\n",
      "  stand_mixer: 70 images (id: 42)\n",
      "  toaster: 70 images (id: 43)\n",
      "  vacuum_cleaner: 70 images (id: 44)\n",
      "  weighing_scale: 70 images (id: 45)\n",
      "  wifi_router: 70 images (id: 46)\n",
      "  wireless_charger: 70 images (id: 47)\n",
      "  wireless_earbuds: 70 images (id: 48)\n",
      "  wireless_mouse: 70 images (id: 49)\n",
      "Split 'val': Found 1000 images across 50 classes\n",
      "Split 'test': Found 500 images across 50 classes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([50]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([50, 2048]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 20 epochs...\n",
      "Train batches: 438, Val batches: 250, Test batches: 125\n",
      "Epoch [1/20], Batch [0/438], Loss: 3.9145, Accuracy: 0.00%\n",
      "Epoch [1/20], Batch [50/438], Loss: 3.8883, Accuracy: 3.43%\n",
      "Epoch [1/20], Batch [100/438], Loss: 3.8463, Accuracy: 3.09%\n",
      "Epoch [1/20], Batch [150/438], Loss: 3.8892, Accuracy: 4.22%\n",
      "Epoch [1/20], Batch [200/438], Loss: 3.7188, Accuracy: 5.29%\n",
      "Epoch [1/20], Batch [250/438], Loss: 3.7810, Accuracy: 7.42%\n",
      "Epoch [1/20], Batch [300/438], Loss: 3.4793, Accuracy: 9.93%\n",
      "Epoch [1/20], Batch [350/438], Loss: 3.2624, Accuracy: 12.29%\n",
      "Epoch [1/20], Batch [400/438], Loss: 3.3360, Accuracy: 14.84%\n",
      "Validation - Loss: 2.9630, Accuracy: 52.00%\n",
      "\n",
      "Epoch [1/20] Summary:\n",
      "  Train - Loss: 3.6675, Accuracy: 17.40%\n",
      "  Val   - Loss: 2.9630, Accuracy: 52.00%\n",
      "  New best validation accuracy: 52.00%\n",
      "------------------------------------------------------------\n",
      "Epoch [2/20], Batch [0/438], Loss: 3.3366, Accuracy: 50.00%\n",
      "Epoch [2/20], Batch [50/438], Loss: 2.5994, Accuracy: 46.32%\n",
      "Epoch [2/20], Batch [100/438], Loss: 2.5587, Accuracy: 46.29%\n",
      "Epoch [2/20], Batch [150/438], Loss: 2.4661, Accuracy: 47.10%\n",
      "Epoch [2/20], Batch [200/438], Loss: 2.3363, Accuracy: 46.83%\n",
      "Epoch [2/20], Batch [250/438], Loss: 1.9457, Accuracy: 48.46%\n",
      "Epoch [2/20], Batch [300/438], Loss: 2.1498, Accuracy: 48.75%\n",
      "Epoch [2/20], Batch [350/438], Loss: 2.0425, Accuracy: 50.14%\n",
      "Epoch [2/20], Batch [400/438], Loss: 1.7100, Accuracy: 51.50%\n",
      "Validation - Loss: 1.2607, Accuracy: 70.70%\n",
      "\n",
      "Epoch [2/20] Summary:\n",
      "  Train - Loss: 2.3615, Accuracy: 51.97%\n",
      "  Val   - Loss: 1.2607, Accuracy: 70.70%\n",
      "  New best validation accuracy: 70.70%\n",
      "------------------------------------------------------------\n",
      "Epoch [3/20], Batch [0/438], Loss: 1.9052, Accuracy: 62.50%\n",
      "Epoch [3/20], Batch [50/438], Loss: 1.7285, Accuracy: 66.42%\n",
      "Epoch [3/20], Batch [100/438], Loss: 1.5649, Accuracy: 66.58%\n",
      "Epoch [3/20], Batch [150/438], Loss: 1.8435, Accuracy: 66.39%\n",
      "Epoch [3/20], Batch [200/438], Loss: 1.3188, Accuracy: 67.29%\n",
      "Epoch [3/20], Batch [250/438], Loss: 1.1085, Accuracy: 67.23%\n",
      "Epoch [3/20], Batch [300/438], Loss: 1.8591, Accuracy: 66.74%\n",
      "Epoch [3/20], Batch [350/438], Loss: 1.3567, Accuracy: 66.92%\n",
      "Epoch [3/20], Batch [400/438], Loss: 1.2549, Accuracy: 67.49%\n",
      "Validation - Loss: 0.7512, Accuracy: 77.20%\n",
      "\n",
      "Epoch [3/20] Summary:\n",
      "  Train - Loss: 1.4298, Accuracy: 67.51%\n",
      "  Val   - Loss: 0.7512, Accuracy: 77.20%\n",
      "  New best validation accuracy: 77.20%\n",
      "------------------------------------------------------------\n",
      "Epoch [4/20], Batch [0/438], Loss: 1.1608, Accuracy: 75.00%\n",
      "Epoch [4/20], Batch [50/438], Loss: 1.1863, Accuracy: 74.02%\n",
      "Epoch [4/20], Batch [100/438], Loss: 0.8226, Accuracy: 74.26%\n",
      "Epoch [4/20], Batch [150/438], Loss: 1.0435, Accuracy: 73.43%\n",
      "Epoch [4/20], Batch [200/438], Loss: 1.3757, Accuracy: 73.13%\n",
      "Epoch [4/20], Batch [250/438], Loss: 1.4979, Accuracy: 72.91%\n",
      "Epoch [4/20], Batch [300/438], Loss: 1.6681, Accuracy: 72.76%\n",
      "Epoch [4/20], Batch [350/438], Loss: 1.2150, Accuracy: 72.58%\n",
      "Epoch [4/20], Batch [400/438], Loss: 1.0010, Accuracy: 72.60%\n",
      "Validation - Loss: 0.5702, Accuracy: 80.80%\n",
      "\n",
      "Epoch [4/20] Summary:\n",
      "  Train - Loss: 1.0375, Accuracy: 72.66%\n",
      "  Val   - Loss: 0.5702, Accuracy: 80.80%\n",
      "  New best validation accuracy: 80.80%\n",
      "------------------------------------------------------------\n",
      "Epoch [5/20], Batch [0/438], Loss: 0.4105, Accuracy: 100.00%\n",
      "Epoch [5/20], Batch [50/438], Loss: 0.6798, Accuracy: 76.47%\n",
      "Epoch [5/20], Batch [100/438], Loss: 1.6009, Accuracy: 75.62%\n",
      "Epoch [5/20], Batch [150/438], Loss: 0.3546, Accuracy: 76.24%\n",
      "Epoch [5/20], Batch [200/438], Loss: 0.3860, Accuracy: 75.50%\n",
      "Epoch [5/20], Batch [250/438], Loss: 0.7993, Accuracy: 75.75%\n",
      "Epoch [5/20], Batch [300/438], Loss: 1.4660, Accuracy: 76.29%\n",
      "Epoch [5/20], Batch [350/438], Loss: 1.2044, Accuracy: 76.39%\n",
      "Epoch [5/20], Batch [400/438], Loss: 0.3200, Accuracy: 76.75%\n",
      "Validation - Loss: 0.4877, Accuracy: 84.20%\n",
      "\n",
      "Epoch [5/20] Summary:\n",
      "  Train - Loss: 0.8397, Accuracy: 76.89%\n",
      "  Val   - Loss: 0.4877, Accuracy: 84.20%\n",
      "  New best validation accuracy: 84.20%\n",
      "------------------------------------------------------------\n",
      "Epoch [6/20], Batch [0/438], Loss: 1.2559, Accuracy: 50.00%\n",
      "Epoch [6/20], Batch [50/438], Loss: 0.7313, Accuracy: 82.60%\n",
      "Epoch [6/20], Batch [100/438], Loss: 0.3844, Accuracy: 80.57%\n",
      "Epoch [6/20], Batch [150/438], Loss: 0.5493, Accuracy: 80.46%\n",
      "Epoch [6/20], Batch [200/438], Loss: 0.2425, Accuracy: 80.66%\n",
      "Epoch [6/20], Batch [250/438], Loss: 0.6116, Accuracy: 80.53%\n",
      "Epoch [6/20], Batch [300/438], Loss: 0.8208, Accuracy: 79.98%\n",
      "Epoch [6/20], Batch [350/438], Loss: 0.7253, Accuracy: 79.59%\n",
      "Epoch [6/20], Batch [400/438], Loss: 0.3434, Accuracy: 80.08%\n",
      "Validation - Loss: 0.3958, Accuracy: 85.80%\n",
      "\n",
      "Epoch [6/20] Summary:\n",
      "  Train - Loss: 0.6726, Accuracy: 80.40%\n",
      "  Val   - Loss: 0.3958, Accuracy: 85.80%\n",
      "  New best validation accuracy: 85.80%\n",
      "------------------------------------------------------------\n",
      "Epoch [7/20], Batch [0/438], Loss: 0.7052, Accuracy: 87.50%\n",
      "Epoch [7/20], Batch [50/438], Loss: 0.3544, Accuracy: 85.05%\n",
      "Epoch [7/20], Batch [100/438], Loss: 0.7175, Accuracy: 83.42%\n",
      "Epoch [7/20], Batch [150/438], Loss: 0.6521, Accuracy: 83.53%\n",
      "Epoch [7/20], Batch [200/438], Loss: 0.1858, Accuracy: 83.64%\n",
      "Epoch [7/20], Batch [250/438], Loss: 0.6343, Accuracy: 83.67%\n",
      "Epoch [7/20], Batch [300/438], Loss: 0.3389, Accuracy: 84.05%\n",
      "Epoch [7/20], Batch [350/438], Loss: 0.2902, Accuracy: 83.73%\n",
      "Epoch [7/20], Batch [400/438], Loss: 1.0279, Accuracy: 83.26%\n",
      "Validation - Loss: 0.3746, Accuracy: 86.50%\n",
      "\n",
      "Epoch [7/20] Summary:\n",
      "  Train - Loss: 0.5836, Accuracy: 83.17%\n",
      "  Val   - Loss: 0.3746, Accuracy: 86.50%\n",
      "  New best validation accuracy: 86.50%\n",
      "------------------------------------------------------------\n",
      "Epoch [8/20], Batch [0/438], Loss: 0.5071, Accuracy: 87.50%\n",
      "Epoch [8/20], Batch [50/438], Loss: 0.8723, Accuracy: 82.11%\n",
      "Epoch [8/20], Batch [100/438], Loss: 0.2173, Accuracy: 84.78%\n",
      "Epoch [8/20], Batch [150/438], Loss: 0.6112, Accuracy: 86.34%\n",
      "Epoch [8/20], Batch [200/438], Loss: 0.7032, Accuracy: 85.95%\n",
      "Epoch [8/20], Batch [250/438], Loss: 0.2754, Accuracy: 85.41%\n",
      "Epoch [8/20], Batch [300/438], Loss: 1.8402, Accuracy: 85.01%\n",
      "Epoch [8/20], Batch [350/438], Loss: 0.2213, Accuracy: 85.22%\n",
      "Epoch [8/20], Batch [400/438], Loss: 0.4051, Accuracy: 85.26%\n",
      "Validation - Loss: 0.3370, Accuracy: 88.20%\n",
      "\n",
      "Epoch [8/20] Summary:\n",
      "  Train - Loss: 0.5093, Accuracy: 85.34%\n",
      "  Val   - Loss: 0.3370, Accuracy: 88.20%\n",
      "  New best validation accuracy: 88.20%\n",
      "------------------------------------------------------------\n",
      "Epoch [9/20], Batch [0/438], Loss: 0.2315, Accuracy: 87.50%\n",
      "Epoch [9/20], Batch [50/438], Loss: 0.5019, Accuracy: 85.54%\n",
      "Epoch [9/20], Batch [100/438], Loss: 0.2196, Accuracy: 86.39%\n",
      "Epoch [9/20], Batch [150/438], Loss: 0.7025, Accuracy: 87.00%\n",
      "Epoch [9/20], Batch [200/438], Loss: 0.5250, Accuracy: 86.94%\n",
      "Epoch [9/20], Batch [250/438], Loss: 0.4456, Accuracy: 87.15%\n",
      "Epoch [9/20], Batch [300/438], Loss: 0.4471, Accuracy: 87.29%\n",
      "Epoch [9/20], Batch [350/438], Loss: 0.1318, Accuracy: 87.18%\n",
      "Epoch [9/20], Batch [400/438], Loss: 0.0983, Accuracy: 87.03%\n",
      "Validation - Loss: 0.3145, Accuracy: 88.40%\n",
      "\n",
      "Epoch [9/20] Summary:\n",
      "  Train - Loss: 0.4350, Accuracy: 87.03%\n",
      "  Val   - Loss: 0.3145, Accuracy: 88.40%\n",
      "  New best validation accuracy: 88.40%\n",
      "------------------------------------------------------------\n",
      "Epoch [10/20], Batch [0/438], Loss: 0.7895, Accuracy: 87.50%\n",
      "Epoch [10/20], Batch [50/438], Loss: 0.3521, Accuracy: 86.03%\n",
      "Epoch [10/20], Batch [100/438], Loss: 0.4277, Accuracy: 86.76%\n",
      "Epoch [10/20], Batch [150/438], Loss: 0.1760, Accuracy: 86.92%\n",
      "Epoch [10/20], Batch [200/438], Loss: 0.5807, Accuracy: 87.62%\n",
      "Epoch [10/20], Batch [250/438], Loss: 0.6314, Accuracy: 88.00%\n",
      "Epoch [10/20], Batch [300/438], Loss: 0.4949, Accuracy: 88.16%\n",
      "Epoch [10/20], Batch [350/438], Loss: 0.3301, Accuracy: 88.46%\n",
      "Epoch [10/20], Batch [400/438], Loss: 0.1159, Accuracy: 88.62%\n",
      "Validation - Loss: 0.2807, Accuracy: 89.10%\n",
      "\n",
      "Epoch [10/20] Summary:\n",
      "  Train - Loss: 0.3867, Accuracy: 88.34%\n",
      "  Val   - Loss: 0.2807, Accuracy: 89.10%\n",
      "  New best validation accuracy: 89.10%\n",
      "------------------------------------------------------------\n",
      "Epoch [11/20], Batch [0/438], Loss: 0.1461, Accuracy: 100.00%\n",
      "Epoch [11/20], Batch [50/438], Loss: 0.2816, Accuracy: 89.22%\n",
      "Epoch [11/20], Batch [100/438], Loss: 0.0974, Accuracy: 89.48%\n",
      "Epoch [11/20], Batch [150/438], Loss: 0.1568, Accuracy: 89.24%\n",
      "Epoch [11/20], Batch [200/438], Loss: 0.3976, Accuracy: 89.55%\n",
      "Epoch [11/20], Batch [250/438], Loss: 0.1873, Accuracy: 89.59%\n",
      "Epoch [11/20], Batch [300/438], Loss: 0.2054, Accuracy: 89.78%\n",
      "Epoch [11/20], Batch [350/438], Loss: 0.3024, Accuracy: 89.64%\n",
      "Epoch [11/20], Batch [400/438], Loss: 0.2073, Accuracy: 89.81%\n",
      "Validation - Loss: 0.2744, Accuracy: 89.80%\n",
      "\n",
      "Epoch [11/20] Summary:\n",
      "  Train - Loss: 0.3551, Accuracy: 89.97%\n",
      "  Val   - Loss: 0.2744, Accuracy: 89.80%\n",
      "  New best validation accuracy: 89.80%\n",
      "------------------------------------------------------------\n",
      "Epoch [12/20], Batch [0/438], Loss: 0.4976, Accuracy: 87.50%\n",
      "Epoch [12/20], Batch [50/438], Loss: 0.1266, Accuracy: 88.73%\n",
      "Epoch [12/20], Batch [100/438], Loss: 0.1932, Accuracy: 90.47%\n",
      "Epoch [12/20], Batch [150/438], Loss: 0.3002, Accuracy: 90.15%\n",
      "Epoch [12/20], Batch [200/438], Loss: 0.3691, Accuracy: 90.05%\n",
      "Epoch [12/20], Batch [250/438], Loss: 0.3648, Accuracy: 89.89%\n",
      "Epoch [12/20], Batch [300/438], Loss: 0.3625, Accuracy: 89.74%\n",
      "Epoch [12/20], Batch [350/438], Loss: 0.0669, Accuracy: 89.85%\n",
      "Epoch [12/20], Batch [400/438], Loss: 0.1611, Accuracy: 90.24%\n",
      "Validation - Loss: 0.2614, Accuracy: 89.90%\n",
      "\n",
      "Epoch [12/20] Summary:\n",
      "  Train - Loss: 0.3180, Accuracy: 90.37%\n",
      "  Val   - Loss: 0.2614, Accuracy: 89.90%\n",
      "  New best validation accuracy: 89.90%\n",
      "------------------------------------------------------------\n",
      "Epoch [13/20], Batch [0/438], Loss: 0.3627, Accuracy: 87.50%\n",
      "Epoch [13/20], Batch [50/438], Loss: 0.1782, Accuracy: 91.67%\n",
      "Epoch [13/20], Batch [100/438], Loss: 0.2000, Accuracy: 90.59%\n",
      "Epoch [13/20], Batch [150/438], Loss: 0.2094, Accuracy: 91.31%\n",
      "Epoch [13/20], Batch [200/438], Loss: 0.2091, Accuracy: 91.48%\n",
      "Epoch [13/20], Batch [250/438], Loss: 0.1115, Accuracy: 91.63%\n",
      "Epoch [13/20], Batch [300/438], Loss: 0.0390, Accuracy: 91.28%\n",
      "Epoch [13/20], Batch [350/438], Loss: 0.5323, Accuracy: 90.99%\n",
      "Epoch [13/20], Batch [400/438], Loss: 0.2835, Accuracy: 90.74%\n",
      "Validation - Loss: 0.2385, Accuracy: 90.20%\n",
      "\n",
      "Epoch [13/20] Summary:\n",
      "  Train - Loss: 0.2910, Accuracy: 90.57%\n",
      "  Val   - Loss: 0.2385, Accuracy: 90.20%\n",
      "  New best validation accuracy: 90.20%\n",
      "------------------------------------------------------------\n",
      "Epoch [14/20], Batch [0/438], Loss: 0.2661, Accuracy: 100.00%\n",
      "Epoch [14/20], Batch [50/438], Loss: 0.5329, Accuracy: 91.42%\n",
      "Epoch [14/20], Batch [100/438], Loss: 0.1420, Accuracy: 91.58%\n",
      "Epoch [14/20], Batch [150/438], Loss: 0.2786, Accuracy: 91.56%\n",
      "Epoch [14/20], Batch [200/438], Loss: 0.1880, Accuracy: 91.54%\n",
      "Epoch [14/20], Batch [250/438], Loss: 0.0459, Accuracy: 91.53%\n",
      "Epoch [14/20], Batch [300/438], Loss: 0.3737, Accuracy: 91.45%\n",
      "Epoch [14/20], Batch [350/438], Loss: 0.1832, Accuracy: 91.35%\n",
      "Epoch [14/20], Batch [400/438], Loss: 0.2201, Accuracy: 91.37%\n",
      "Validation - Loss: 0.2359, Accuracy: 91.10%\n",
      "\n",
      "Epoch [14/20] Summary:\n",
      "  Train - Loss: 0.2716, Accuracy: 91.37%\n",
      "  Val   - Loss: 0.2359, Accuracy: 91.10%\n",
      "  New best validation accuracy: 91.10%\n",
      "------------------------------------------------------------\n",
      "Epoch [15/20], Batch [0/438], Loss: 0.1317, Accuracy: 100.00%\n",
      "Epoch [15/20], Batch [50/438], Loss: 0.3756, Accuracy: 93.87%\n",
      "Epoch [15/20], Batch [100/438], Loss: 0.1185, Accuracy: 94.43%\n",
      "Epoch [15/20], Batch [150/438], Loss: 0.1138, Accuracy: 94.04%\n",
      "Epoch [15/20], Batch [200/438], Loss: 0.1504, Accuracy: 93.84%\n",
      "Epoch [15/20], Batch [250/438], Loss: 0.1828, Accuracy: 93.92%\n",
      "Epoch [15/20], Batch [300/438], Loss: 0.1662, Accuracy: 93.73%\n",
      "Epoch [15/20], Batch [350/438], Loss: 0.0709, Accuracy: 93.20%\n",
      "Epoch [15/20], Batch [400/438], Loss: 0.3235, Accuracy: 92.92%\n",
      "Validation - Loss: 0.2309, Accuracy: 91.60%\n",
      "\n",
      "Epoch [15/20] Summary:\n",
      "  Train - Loss: 0.2290, Accuracy: 92.94%\n",
      "  Val   - Loss: 0.2309, Accuracy: 91.60%\n",
      "  New best validation accuracy: 91.60%\n",
      "------------------------------------------------------------\n",
      "Epoch [16/20], Batch [0/438], Loss: 0.0703, Accuracy: 100.00%\n",
      "Epoch [16/20], Batch [50/438], Loss: 0.2840, Accuracy: 94.61%\n",
      "Epoch [16/20], Batch [100/438], Loss: 0.0697, Accuracy: 93.44%\n",
      "Epoch [16/20], Batch [150/438], Loss: 0.2035, Accuracy: 93.96%\n",
      "Epoch [16/20], Batch [200/438], Loss: 0.2071, Accuracy: 93.84%\n",
      "Epoch [16/20], Batch [250/438], Loss: 0.0719, Accuracy: 93.82%\n",
      "Epoch [16/20], Batch [300/438], Loss: 0.0231, Accuracy: 93.65%\n",
      "Epoch [16/20], Batch [350/438], Loss: 0.0879, Accuracy: 93.84%\n",
      "Epoch [16/20], Batch [400/438], Loss: 0.1466, Accuracy: 93.45%\n",
      "Validation - Loss: 0.2217, Accuracy: 92.00%\n",
      "\n",
      "Epoch [16/20] Summary:\n",
      "  Train - Loss: 0.2183, Accuracy: 93.20%\n",
      "  Val   - Loss: 0.2217, Accuracy: 92.00%\n",
      "  New best validation accuracy: 92.00%\n",
      "------------------------------------------------------------\n",
      "Epoch [17/20], Batch [0/438], Loss: 0.0272, Accuracy: 100.00%\n",
      "Epoch [17/20], Batch [50/438], Loss: 0.0715, Accuracy: 96.32%\n",
      "Epoch [17/20], Batch [100/438], Loss: 0.1397, Accuracy: 94.31%\n",
      "Epoch [17/20], Batch [150/438], Loss: 0.3528, Accuracy: 93.54%\n",
      "Epoch [17/20], Batch [200/438], Loss: 0.1247, Accuracy: 93.41%\n",
      "Epoch [17/20], Batch [250/438], Loss: 1.1266, Accuracy: 93.33%\n",
      "Epoch [17/20], Batch [300/438], Loss: 0.0844, Accuracy: 93.02%\n",
      "Epoch [17/20], Batch [350/438], Loss: 0.2727, Accuracy: 92.74%\n",
      "Epoch [17/20], Batch [400/438], Loss: 0.1886, Accuracy: 92.80%\n",
      "Validation - Loss: 0.2088, Accuracy: 92.30%\n",
      "\n",
      "Epoch [17/20] Summary:\n",
      "  Train - Loss: 0.2136, Accuracy: 92.86%\n",
      "  Val   - Loss: 0.2088, Accuracy: 92.30%\n",
      "  New best validation accuracy: 92.30%\n",
      "------------------------------------------------------------\n",
      "Epoch [18/20], Batch [0/438], Loss: 0.3351, Accuracy: 87.50%\n",
      "Epoch [18/20], Batch [50/438], Loss: 0.0168, Accuracy: 95.83%\n",
      "Epoch [18/20], Batch [100/438], Loss: 0.1795, Accuracy: 95.42%\n",
      "Epoch [18/20], Batch [150/438], Loss: 0.2512, Accuracy: 95.20%\n",
      "Epoch [18/20], Batch [200/438], Loss: 0.0548, Accuracy: 94.90%\n",
      "Epoch [18/20], Batch [250/438], Loss: 0.1220, Accuracy: 94.87%\n",
      "Epoch [18/20], Batch [300/438], Loss: 0.2625, Accuracy: 94.81%\n",
      "Epoch [18/20], Batch [350/438], Loss: 0.1713, Accuracy: 94.41%\n",
      "Epoch [18/20], Batch [400/438], Loss: 0.4493, Accuracy: 94.36%\n",
      "Validation - Loss: 0.2083, Accuracy: 93.20%\n",
      "\n",
      "Epoch [18/20] Summary:\n",
      "  Train - Loss: 0.1849, Accuracy: 94.40%\n",
      "  Val   - Loss: 0.2083, Accuracy: 93.20%\n",
      "  New best validation accuracy: 93.20%\n",
      "------------------------------------------------------------\n",
      "Epoch [19/20], Batch [0/438], Loss: 0.1164, Accuracy: 100.00%\n",
      "Epoch [19/20], Batch [50/438], Loss: 0.4766, Accuracy: 95.83%\n",
      "Epoch [19/20], Batch [100/438], Loss: 0.0189, Accuracy: 95.92%\n",
      "Epoch [19/20], Batch [150/438], Loss: 0.2545, Accuracy: 95.94%\n",
      "Epoch [19/20], Batch [200/438], Loss: 0.0677, Accuracy: 95.71%\n",
      "Epoch [19/20], Batch [250/438], Loss: 0.2854, Accuracy: 95.27%\n",
      "Epoch [19/20], Batch [300/438], Loss: 0.0566, Accuracy: 94.52%\n",
      "Epoch [19/20], Batch [350/438], Loss: 0.1963, Accuracy: 94.55%\n",
      "Epoch [19/20], Batch [400/438], Loss: 0.0283, Accuracy: 94.39%\n",
      "Validation - Loss: 0.2048, Accuracy: 92.50%\n",
      "\n",
      "Epoch [19/20] Summary:\n",
      "  Train - Loss: 0.1711, Accuracy: 94.49%\n",
      "  Val   - Loss: 0.2048, Accuracy: 92.50%\n",
      "------------------------------------------------------------\n",
      "Epoch [20/20], Batch [0/438], Loss: 0.2282, Accuracy: 87.50%\n",
      "Epoch [20/20], Batch [50/438], Loss: 0.1785, Accuracy: 97.06%\n",
      "Epoch [20/20], Batch [100/438], Loss: 0.1554, Accuracy: 96.29%\n",
      "Epoch [20/20], Batch [150/438], Loss: 0.1621, Accuracy: 95.86%\n",
      "Epoch [20/20], Batch [200/438], Loss: 0.0095, Accuracy: 95.71%\n",
      "Epoch [20/20], Batch [250/438], Loss: 0.3492, Accuracy: 95.47%\n",
      "Epoch [20/20], Batch [300/438], Loss: 0.1296, Accuracy: 95.22%\n",
      "Epoch [20/20], Batch [350/438], Loss: 0.1638, Accuracy: 95.19%\n",
      "Epoch [20/20], Batch [400/438], Loss: 0.4296, Accuracy: 95.14%\n",
      "Validation - Loss: 0.2020, Accuracy: 92.80%\n",
      "\n",
      "Epoch [20/20] Summary:\n",
      "  Train - Loss: 0.1526, Accuracy: 95.20%\n",
      "  Val   - Loss: 0.2020, Accuracy: 92.80%\n",
      "------------------------------------------------------------\n",
      "Test - Loss: 0.2875, Accuracy: 92.00%\n",
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "Best Validation Accuracy: 93.20%\n",
      "Test Accuracy: 92.00%\n",
      "Model saved at: classifier_finetuned\n",
      "Files saved:\n",
      "  - Model weights: classifier_finetuned/pytorch_model.bin\n",
      "  - Model config: classifier_finetuned/config.json\n",
      "  - Processor config: classifier_finetuned/preprocessor_config.json\n",
      "  - Training metadata: classifier_finetuned/training_metadata.json\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    cfg = ModelConfig()\n",
    "    print(f\"Using device: {cfg.device}\")\n",
    "    \n",
    "    try:\n",
    "        temp_processor = AutoImageProcessor.from_pretrained(cfg.model_name)\n",
    "        \n",
    "        print(\"Creating datasets...\")\n",
    "        train_dataset = AmazonDataset(cfg.input_dir, temp_processor, cfg.image_size, 'train', cfg.use_augmentation)\n",
    "        val_dataset = AmazonDataset(cfg.input_dir, temp_processor, cfg.image_size, 'val', False)\n",
    "        test_dataset = AmazonDataset(cfg.input_dir, temp_processor, cfg.image_size, 'test', False)\n",
    "        \n",
    "        num_labels = len(train_dataset.label2id)\n",
    "        \n",
    "        config = AutoConfig.from_pretrained(cfg.model_name)\n",
    "        config.num_labels = num_labels\n",
    "        config.id2label = train_dataset.id2label\n",
    "        config.label2id = train_dataset.label2id\n",
    "        \n",
    "        model = AutoModelForImageClassification.from_pretrained(\n",
    "            cfg.model_name, \n",
    "            config=config,\n",
    "            ignore_mismatched_sizes=True \n",
    "        )\n",
    "        \n",
    "        processor = AutoImageProcessor.from_pretrained(cfg.model_name)\n",
    "        model.to(cfg.device)\n",
    "        \n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=cfg.train_batch_size, \n",
    "            shuffle=True, \n",
    "            collate_fn=collate_fn,\n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        val_dataloader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=cfg.eval_batch_size, \n",
    "            shuffle=False, \n",
    "            collate_fn=collate_fn,\n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset, \n",
    "            batch_size=cfg.eval_batch_size, \n",
    "            shuffle=False, \n",
    "            collate_fn=collate_fn,\n",
    "            num_workers=0\n",
    "        )\n",
    "\n",
    "        optimizer = AdamW(model.parameters(), lr=cfg.learning_rate, weight_decay=0.01)\n",
    "        \n",
    "        print(f\"Starting training for {cfg.num_epochs} epochs...\")\n",
    "        print(f\"Train batches: {len(train_dataloader)}, Val batches: {len(val_dataloader)}, Test batches: {len(test_dataloader)}\")\n",
    "        \n",
    "        best_val_accuracy = 0\n",
    "        best_model_state = None\n",
    "        \n",
    "        for epoch in range(cfg.num_epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            correct_predictions = 0\n",
    "            total_predictions = 0\n",
    "            \n",
    "            for batch_idx, batch in enumerate(train_dataloader):\n",
    "                try:\n",
    "                    pixel_values = batch[\"pixel_values\"].to(cfg.device)\n",
    "                    labels = batch[\"labels\"].to(cfg.device)\n",
    "\n",
    "                    outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "                    loss = outputs.loss\n",
    "                    logits = outputs.logits\n",
    "\n",
    "                    predictions = torch.argmax(logits, dim=-1)\n",
    "                    correct_predictions += (predictions == labels).sum().item()\n",
    "                    total_predictions += labels.size(0)\n",
    "\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    total_loss += loss.item()\n",
    "                    \n",
    "                    if batch_idx % 50 == 0:  # Print less frequently\n",
    "                        accuracy = correct_predictions / total_predictions * 100\n",
    "                        print(f\"Epoch [{epoch+1}/{cfg.num_epochs}], \"\n",
    "                              f\"Batch [{batch_idx}/{len(train_dataloader)}], \"\n",
    "                              f\"Loss: {loss.item():.4f}, \"\n",
    "                              f\"Accuracy: {accuracy:.2f}%\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error in batch {batch_idx}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            avg_train_loss = total_loss / len(train_dataloader)\n",
    "            train_accuracy = correct_predictions / total_predictions * 100\n",
    "            \n",
    "            val_loss, val_accuracy = evaluate_model(model, val_dataloader, cfg.device, \"Validation\")\n",
    "            \n",
    "            print(f\"\\nEpoch [{epoch+1}/{cfg.num_epochs}] Summary:\")\n",
    "            print(f\"  Train - Loss: {avg_train_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "            print(f\"  Val   - Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\")\n",
    "            \n",
    "            if val_accuracy > best_val_accuracy:\n",
    "                best_val_accuracy = val_accuracy\n",
    "                best_model_state = model.state_dict().copy()\n",
    "                print(f\"  New best validation accuracy: {best_val_accuracy:.2f}%\")\n",
    "            \n",
    "            print(\"-\" * 60)\n",
    "\n",
    "        if best_model_state is not None:\n",
    "            model.load_state_dict(best_model_state)\n",
    "        \n",
    "        test_loss , test_accuracy = evaluate_model(model, test_dataloader, cfg.device, \"Test\")\n",
    "        \n",
    "        os.makedirs(cfg.output_dir, exist_ok=True)\n",
    "        model.save_pretrained(cfg.output_dir)\n",
    "        processor.save_pretrained(cfg.output_dir)\n",
    "        \n",
    "        metadata = {\n",
    "            'label2id': train_dataset.label2id,\n",
    "            'id2label': train_dataset.id2label,\n",
    "            'best_val_accuracy': best_val_accuracy,\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'num_classes': num_labels,\n",
    "            'train_samples': len(train_dataset),\n",
    "            'val_samples': len(val_dataset),\n",
    "            'test_samples': len(test_dataset),\n",
    "            'model_config': {\n",
    "                'model_name': cfg.model_name,\n",
    "                'image_size': cfg.image_size,\n",
    "                'num_epochs': cfg.num_epochs,\n",
    "                'learning_rate': cfg.learning_rate,\n",
    "                'batch_size': cfg.train_batch_size,\n",
    "                'augmentation': cfg.use_augmentation\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(cfg.output_dir, 'training_metadata.json'), 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"TRAINING COMPLETE\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Best Validation Accuracy: {best_val_accuracy:.2f}%\")\n",
    "        print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "        print(f\"Model saved at: {cfg.output_dir}\")\n",
    "        print(\"Files saved:\")\n",
    "        print(f\"  - Model weights: {cfg.output_dir}/pytorch_model.bin\")\n",
    "        print(f\"  - Model config: {cfg.output_dir}/config.json\")\n",
    "        print(f\"  - Processor config: {cfg.output_dir}/preprocessor_config.json\")\n",
    "        print(f\"  - Training metadata: {cfg.output_dir}/training_metadata.json\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "def test_model():\n",
    "    cfg = ModelConfig()\n",
    "    \n",
    "    try:\n",
    "        model = AutoModelForImageClassification.from_pretrained(cfg.output_dir)\n",
    "        processor = AutoImageProcessor.from_pretrained(cfg.output_dir)\n",
    "        \n",
    "        with open(os.path.join(cfg.output_dir, 'training_metadata.json'), 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "            id2label = {int(k): v for k, v in metadata['id2label'].items()}\n",
    "        \n",
    "        model.eval()\n",
    "        model.to(cfg.device)\n",
    "        \n",
    "        print(\"Model loaded successfully!\")\n",
    "        print(f\"Test Accuracy: {metadata['test_accuracy']:.2f}%\")\n",
    "        print(\"Available classes:\", list(id2label.values()))\n",
    "        \n",
    "        def predict_image(image_path):\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            inputs = processor(image, return_tensors=\"pt\").to(cfg.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "                predicted_class_id = predictions.argmax().item()\n",
    "                confidence = predictions[0][predicted_class_id].item()\n",
    "                \n",
    "            return id2label[predicted_class_id], confidence\n",
    "        \n",
    "        return predict_image\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    random.seed(42)\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(42)\n",
    "    \n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a21d44d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af9e793",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
